Using cache found in /home/studio-lab-user/.cache/torch/hub/facebookresearch_deit_main
Training epoch 0:   0%|                                                                                                                                                                                                         | 0/74 [00:00<?, ?it/s]
Archive found at AdaViT/imagenette_dataset/imagenette.zip, skipping download
Extracted file found at AdaViT/imagenette_dataset/imagenette2-160, skipping extraction
Warning: num_classes is not used for Imagenette dataset.
Ignoring the argument and using default number of classes in this dataset (10).
Loading timm pretrained weights:  ['facebookresearch/deit:main', 'deit_tiny_patch16_224']
Downloading timm pretrained weights:  ['facebookresearch/deit:main', 'deit_tiny_patch16_224']
Loading weights for a different number of classes. Replacing head with random weights. You should fine-tune the model.
The Model is:  AdaptiveVisionTransformer(
  (conv_proj): Conv2d(3, 192, kernel_size=(16, 16), stride=(16, 16))
  (encoder): AViTEncoder(
    (dropout): Dropout(p=0.0, inplace=False)
    (layers): ModuleList(
      (0-11): 12 x AViTBlock(
        (ln_1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
        (self_attention): SelfAttention(
          (self_attention): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=192, out_features=192, bias=True)
          )
        )
        (dropout): Dropout(p=0.0, inplace=False)
        (ln_2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
        (mlp): MLP(
          (fc1): Linear(in_features=192, out_features=768, bias=True)
          (fc2): Linear(in_features=768, out_features=192, bias=True)
        )
      )
    )
    (ln): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
  )
  (head): Linear(in_features=192, out_features=10, bias=True)
)
Reinitializing class_tokens... Reinitialized!
Freezing all parameters except for those containing any of these words in their names:  ['gate', 'class', 'head', 'threshold', 'budget']
Trainable parameters: ['class_tokens', 'head.weight', 'head.bias']

Training epoch 0:  11%|████████████████████▊                                                                                                                                                                            | 8/74 [00:06<00:53,  1.23it/s]
Error executing job with overrides: []
Traceback (most recent call last):
  File "/home/studio-lab-user/sagemaker-studiolab-notebooks/AdaViT/train/train.py", line 203, in train
    train_epoch(model, train_loader, optimizer, epoch)
  File "/home/studio-lab-user/sagemaker-studiolab-notebooks/AdaViT/train/train.py", line 110, in train_epoch
    out = model(batch)
  File "/home/studio-lab-user/.conda/envs/studiolab/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/studio-lab-user/.conda/envs/studiolab/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/studio-lab-user/sagemaker-studiolab-notebooks/AdaViT/models/adavit.py", line 635, in forward
    x = self.encoder(x)
  File "/home/studio-lab-user/.conda/envs/studiolab/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/studio-lab-user/.conda/envs/studiolab/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/studio-lab-user/sagemaker-studiolab-notebooks/AdaViT/models/adavit.py", line 334, in forward
    return self.forward_features_act_token(input)
  File "/home/studio-lab-user/sagemaker-studiolab-notebooks/AdaViT/models/adavit.py", line 459, in forward_features_act_token
    mask_token = speed_up_halting(mask_token, new_halted_tokens_per_layer, percentage=self.percentage, discard_level=self.discard_level, patch_width=self.patch_width)
  File "/home/studio-lab-user/sagemaker-studiolab-notebooks/AdaViT/models/adavit.py", line 224, in speed_up_halting
    mask_token[bottom_right_indices[:, 0], bottom_right_indices[:, 1]] = False
RuntimeError: CUDA error: device-side assert triggered
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1.
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.
Set the environment variable HYDRA_FULL_ERROR=1 for a complete stack trace.