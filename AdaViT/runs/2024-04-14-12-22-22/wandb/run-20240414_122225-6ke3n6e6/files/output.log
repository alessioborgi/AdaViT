Archive found at AdaViT/imagenette_dataset/imagenette.zip, skipping download
Extracted file found at AdaViT/imagenette_dataset/imagenette2-160, skipping extraction
Warning: num_classes is not used for Imagenette dataset.
Ignoring the argument and using default number of classes in this dataset (10).
Loading timm pretrained weights:  ['facebookresearch/deit:main', 'deit_tiny_patch16_224']
Downloading timm pretrained weights:  ['facebookresearch/deit:main', 'deit_tiny_patch16_224']
Loading weights for a different number of classes. Replacing head with random weights. You should fine-tune the model.
The Model is:  AdaptiveVisionTransformer(
  (conv_proj): Conv2d(3, 192, kernel_size=(16, 16), stride=(16, 16))
  (encoder): AViTEncoder(
    (dropout): Dropout(p=0.0, inplace=False)
    (layers): ModuleList(
      (0-11): 12 x AViTBlock(
        (ln_1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
        (self_attention): SelfAttention(
          (self_attention): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=192, out_features=192, bias=True)
          )
        )
        (dropout): Dropout(p=0.0, inplace=False)
        (ln_2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
        (mlp): MLP(
          (fc1): Linear(in_features=192, out_features=768, bias=True)
          (fc2): Linear(in_features=768, out_features=192, bias=True)
        )
      )
    )
    (ln): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
  )
  (head): Linear(in_features=192, out_features=10, bias=True)
)
Reinitializing class_tokens... Reinitialized!
Freezing all parameters except for those containing any of these words in their names:  ['gate', 'class', 'head', 'threshold', 'budget']
Trainable parameters: ['class_tokens', 'head.weight', 'head.bias']
Frozen parameters: ['conv_proj.weight', 'conv_proj.bias', 'encoder.pos_embedding', 'encoder.layers.0.ln_1.weight', 'encoder.layers.0.ln_1.bias', 'encoder.layers.0.self_attention.self_attention.in_proj_weight', 'encoder.layers.0.self_attention.self_attention.in_proj_bias', 'encoder.layers.0.self_attention.self_attention.out_proj.weight', 'encoder.layers.0.self_attention.self_attention.out_proj.bias', 'encoder.layers.0.ln_2.weight', 'encoder.layers.0.ln_2.bias', 'encoder.layers.0.mlp.fc1.weight', 'encoder.layers.0.mlp.fc1.bias', 'encoder.layers.0.mlp.fc2.weight', 'encoder.layers.0.mlp.fc2.bias', 'encoder.layers.1.ln_1.weight', 'encoder.layers.1.ln_1.bias', 'encoder.layers.1.self_attention.self_attention.in_proj_weight', 'encoder.layers.1.self_attention.self_attention.in_proj_bias', 'encoder.layers.1.self_attention.self_attention.out_proj.weight', 'encoder.layers.1.self_attention.self_attention.out_proj.bias', 'encoder.layers.1.ln_2.weight', 'encoder.layers.1.ln_2.bias', 'encoder.layers.1.mlp.fc1.weight', 'encoder.layers.1.mlp.fc1.bias', 'encoder.layers.1.mlp.fc2.weight', 'encoder.layers.1.mlp.fc2.bias', 'encoder.layers.2.ln_1.weight', 'encoder.layers.2.ln_1.bias', 'encoder.layers.2.self_attention.self_attention.in_proj_weight', 'encoder.layers.2.self_attention.self_attention.in_proj_bias', 'encoder.layers.2.self_attention.self_attention.out_proj.weight', 'encoder.layers.2.self_attention.self_attention.out_proj.bias', 'encoder.layers.2.ln_2.weight', 'encoder.layers.2.ln_2.bias', 'encoder.layers.2.mlp.fc1.weight', 'encoder.layers.2.mlp.fc1.bias', 'encoder.layers.2.mlp.fc2.weight', 'encoder.layers.2.mlp.fc2.bias', 'encoder.layers.3.ln_1.weight', 'encoder.layers.3.ln_1.bias', 'encoder.layers.3.self_attention.self_attention.in_proj_weight', 'encoder.layers.3.self_attention.self_attention.in_proj_bias', 'encoder.layers.3.self_attention.self_attention.out_proj.weight', 'encoder.layers.3.self_attention.self_attention.out_proj.bias', 'encoder.layers.3.ln_2.weight', 'encoder.layers.3.ln_2.bias', 'encoder.layers.3.mlp.fc1.weight', 'encoder.layers.3.mlp.fc1.bias', 'encoder.layers.3.mlp.fc2.weight', 'encoder.layers.3.mlp.fc2.bias', 'encoder.layers.4.ln_1.weight', 'encoder.layers.4.ln_1.bias', 'encoder.layers.4.self_attention.self_attention.in_proj_weight', 'encoder.layers.4.self_attention.self_attention.in_proj_bias', 'encoder.layers.4.self_attention.self_attention.out_proj.weight', 'encoder.layers.4.self_attention.self_attention.out_proj.bias', 'encoder.layers.4.ln_2.weight', 'encoder.layers.4.ln_2.bias', 'encoder.layers.4.mlp.fc1.weight', 'encoder.layers.4.mlp.fc1.bias', 'encoder.layers.4.mlp.fc2.weight', 'encoder.layers.4.mlp.fc2.bias', 'encoder.layers.5.ln_1.weight', 'encoder.layers.5.ln_1.bias', 'encoder.layers.5.self_attention.self_attention.in_proj_weight', 'encoder.layers.5.self_attention.self_attention.in_proj_bias', 'encoder.layers.5.self_attention.self_attention.out_proj.weight', 'encoder.layers.5.self_attention.self_attention.out_proj.bias', 'encoder.layers.5.ln_2.weight', 'encoder.layers.5.ln_2.bias', 'encoder.layers.5.mlp.fc1.weight', 'encoder.layers.5.mlp.fc1.bias', 'encoder.layers.5.mlp.fc2.weight', 'encoder.layers.5.mlp.fc2.bias', 'encoder.layers.6.ln_1.weight', 'encoder.layers.6.ln_1.bias', 'encoder.layers.6.self_attention.self_attention.in_proj_weight', 'encoder.layers.6.self_attention.self_attention.in_proj_bias', 'encoder.layers.6.self_attention.self_attention.out_proj.weight', 'encoder.layers.6.self_attention.self_attention.out_proj.bias', 'encoder.layers.6.ln_2.weight', 'encoder.layers.6.ln_2.bias', 'encoder.layers.6.mlp.fc1.weight', 'encoder.layers.6.mlp.fc1.bias', 'encoder.layers.6.mlp.fc2.weight', 'encoder.layers.6.mlp.fc2.bias', 'encoder.layers.7.ln_1.weight', 'encoder.layers.7.ln_1.bias', 'encoder.layers.7.self_attention.self_attention.in_proj_weight', 'encoder.layers.7.self_attention.self_attention.in_proj_bias', 'encoder.layers.7.self_attention.self_attention.out_proj.weight', 'encoder.layers.7.self_attention.self_attention.out_proj.bias', 'encoder.layers.7.ln_2.weight', 'encoder.layers.7.ln_2.bias', 'encoder.layers.7.mlp.fc1.weight', 'encoder.layers.7.mlp.fc1.bias', 'encoder.layers.7.mlp.fc2.weight', 'encoder.layers.7.mlp.fc2.bias', 'encoder.layers.8.ln_1.weight', 'encoder.layers.8.ln_1.bias', 'encoder.layers.8.self_attention.self_attention.in_proj_weight', 'encoder.layers.8.self_attention.self_attention.in_proj_bias', 'encoder.layers.8.self_attention.self_attention.out_proj.weight', 'encoder.layers.8.self_attention.self_attention.out_proj.bias', 'encoder.layers.8.ln_2.weight', 'encoder.layers.8.ln_2.bias', 'encoder.layers.8.mlp.fc1.weight', 'encoder.layers.8.mlp.fc1.bias', 'encoder.layers.8.mlp.fc2.weight', 'encoder.layers.8.mlp.fc2.bias', 'encoder.layers.9.ln_1.weight', 'encoder.layers.9.ln_1.bias', 'encoder.layers.9.self_attention.self_attention.in_proj_weight', 'encoder.layers.9.self_attention.self_attention.in_proj_bias', 'encoder.layers.9.self_attention.self_attention.out_proj.weight', 'encoder.layers.9.self_attention.self_attention.out_proj.bias', 'encoder.layers.9.ln_2.weight', 'encoder.layers.9.ln_2.bias', 'encoder.layers.9.mlp.fc1.weight', 'encoder.layers.9.mlp.fc1.bias', 'encoder.layers.9.mlp.fc2.weight', 'encoder.layers.9.mlp.fc2.bias', 'encoder.layers.10.ln_1.weight', 'encoder.layers.10.ln_1.bias', 'encoder.layers.10.self_attention.self_attention.in_proj_weight', 'encoder.layers.10.self_attention.self_attention.in_proj_bias', 'encoder.layers.10.self_attention.self_attention.out_proj.weight', 'encoder.layers.10.self_attention.self_attention.out_proj.bias', 'encoder.layers.10.ln_2.weight', 'encoder.layers.10.ln_2.bias', 'encoder.layers.10.mlp.fc1.weight', 'encoder.layers.10.mlp.fc1.bias', 'encoder.layers.10.mlp.fc2.weight', 'encoder.layers.10.mlp.fc2.bias', 'encoder.layers.11.ln_1.weight', 'encoder.layers.11.ln_1.bias', 'encoder.layers.11.self_attention.self_attention.in_proj_weight', 'encoder.layers.11.self_attention.self_attention.in_proj_bias', 'encoder.layers.11.self_attention.self_attention.out_proj.weight', 'encoder.layers.11.self_attention.self_attention.out_proj.bias', 'encoder.layers.11.ln_2.weight', 'encoder.layers.11.ln_2.bias', 'encoder.layers.11.mlp.fc1.weight', 'encoder.layers.11.mlp.fc1.bias', 'encoder.layers.11.mlp.fc2.weight', 'encoder.layers.11.mlp.fc2.bias', 'encoder.ln.weight', 'encoder.ln.bias']
Using cache found in /home/studio-lab-user/.cache/torch/hub/facebookresearch_deit_main

Training epoch 0:   3%|█████▍                                                                                                                                                                                                     | 2/74 [00:03<01:34,  1.31s/it]
the shape of the input is:  torch.Size([128, 196, 192])
the shape of the input is:  torch.Size([128, 196, 192])

Training epoch 0:   9%|███████████████████▏                                                                                                                                                                                       | 7/74 [00:04<00:31,  2.11it/s]
the shape of the input is:  torch.Size([128, 196, 192])
the shape of the input is:  torch.Size([128, 196, 192])
the shape of the input is:  torch.Size([128, 196, 192])
the shape of the input is:  torch.Size([128, 196, 192])

Training epoch 0:  16%|████████████████████████████████▊                                                                                                                                                                         | 12/74 [00:06<00:24,  2.49it/s]
the shape of the input is:  torch.Size([128, 196, 192])
the shape of the input is:  torch.Size([128, 196, 192])
the shape of the input is:  torch.Size([128, 196, 192])
the shape of the input is:  torch.Size([128, 196, 192])

Training epoch 0:  23%|██████████████████████████████████████████████▍                                                                                                                                                           | 17/74 [00:08<00:22,  2.56it/s]
the shape of the input is:  torch.Size([128, 196, 192])
the shape of the input is:  torch.Size([128, 196, 192])
the shape of the input is:  torch.Size([128, 196, 192])
the shape of the input is:  torch.Size([128, 196, 192])

Training epoch 0:  30%|████████████████████████████████████████████████████████████                                                                                                                                              | 22/74 [00:10<00:20,  2.58it/s]
the shape of the input is:  torch.Size([128, 196, 192])
the shape of the input is:  torch.Size([128, 196, 192])
the shape of the input is:  torch.Size([128, 196, 192])
the shape of the input is:  torch.Size([128, 196, 192])

Training epoch 0:  36%|█████████████████████████████████████████████████████████████████████████▋                                                                                                                                | 27/74 [00:12<00:18,  2.58it/s]
the shape of the input is:  torch.Size([128, 196, 192])
the shape of the input is:  torch.Size([128, 196, 192])
the shape of the input is:  torch.Size([128, 196, 192])
the shape of the input is:  torch.Size([128, 196, 192])

Training epoch 0:  45%|██████████████████████████████████████████████████████████████████████████████████████████                                                                                                                | 33/74 [00:15<00:15,  2.58it/s]
the shape of the input is:  torch.Size([128, 196, 192])
the shape of the input is:  torch.Size([128, 196, 192])
the shape of the input is:  torch.Size([128, 196, 192])
the shape of the input is:  torch.Size([128, 196, 192])
the shape of the input is:  torch.Size([128, 196, 192])
the shape of the input is:  torch.Size([128, 196, 192])
the shape of the input is:  torch.Size([128, 196, 192])
the shape of the input is:  torch.Size([128, 196, 192])
the shape of the input is:  torch.Size([128, 196, 192])
the shape of the input is:  torch.Size([128, 196, 192])

Training epoch 0:  51%|███████████████████████████████████████████████████████████████████████████████████████████████████████▋                                                                                                  | 38/74 [00:16<00:13,  2.57it/s]
the shape of the input is:  torch.Size([128, 196, 192])
the shape of the input is:  torch.Size([128, 196, 192])
the shape of the input is:  torch.Size([128, 196, 192])
the shape of the input is:  torch.Size([128, 196, 192])

Training epoch 0:  58%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                                                                                    | 43/74 [00:18<00:12,  2.57it/s]
the shape of the input is:  torch.Size([128, 196, 192])
the shape of the input is:  torch.Size([128, 196, 192])
the shape of the input is:  torch.Size([128, 196, 192])
the shape of the input is:  torch.Size([128, 196, 192])

Training epoch 0:  65%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                                                                       | 48/74 [00:20<00:10,  2.57it/s]
the shape of the input is:  torch.Size([128, 196, 192])
the shape of the input is:  torch.Size([128, 196, 192])
the shape of the input is:  torch.Size([128, 196, 192])
the shape of the input is:  torch.Size([128, 196, 192])

Training epoch 0:  72%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                                         | 53/74 [00:22<00:08,  2.57it/s]
the shape of the input is:  torch.Size([128, 196, 192])
the shape of the input is:  torch.Size([128, 196, 192])
the shape of the input is:  torch.Size([128, 196, 192])
the shape of the input is:  torch.Size([128, 196, 192])

Training epoch 0:  78%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                                           | 58/74 [00:24<00:06,  2.57it/s]
the shape of the input is:  torch.Size([128, 196, 192])
the shape of the input is:  torch.Size([128, 196, 192])
the shape of the input is:  torch.Size([128, 196, 192])
the shape of the input is:  torch.Size([128, 196, 192])

Training epoch 0:  86%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                           | 64/74 [00:27<00:03,  2.57it/s]
the shape of the input is:  torch.Size([128, 196, 192])
the shape of the input is:  torch.Size([128, 196, 192])
the shape of the input is:  torch.Size([128, 196, 192])
the shape of the input is:  torch.Size([128, 196, 192])
the shape of the input is:  torch.Size([128, 196, 192])

Training epoch 0:  93%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎             | 69/74 [00:29<00:01,  2.56it/s]
the shape of the input is:  torch.Size([128, 196, 192])
the shape of the input is:  torch.Size([128, 196, 192])
the shape of the input is:  torch.Size([128, 196, 192])
Training epoch 0: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 74/74 [00:31<00:00,  2.38it/s]
Validation epoch 0 :   0%|                                                                                                                                                                                                                | 0/31 [00:00<?, ?it/s]
the shape of the input is:  torch.Size([128, 196, 192])
the shape of the input is:  torch.Size([128, 196, 192])
the shape of the input is:  torch.Size([128, 196, 192])
the shape of the input is:  torch.Size([128, 196, 192])
the shape of the input is:  torch.Size([128, 196, 192])
the shape of the input is:  torch.Size([128, 196, 192])

Validation epoch 0 :  23%|█████████████████████████████████████████████▏                                                                                                                                                          | 7/31 [00:02<00:05,  4.74it/s]
the shape of the input is:  torch.Size([128, 196, 192])
the shape of the input is:  torch.Size([128, 196, 192])
the shape of the input is:  torch.Size([128, 196, 192])
the shape of the input is:  torch.Size([128, 196, 192])
the shape of the input is:  torch.Size([128, 196, 192])
the shape of the input is:  torch.Size([128, 196, 192])
the shape of the input is:  torch.Size([128, 196, 192])
the shape of the input is:  torch.Size([128, 196, 192])
the shape of the input is:  torch.Size([128, 196, 192])
the shape of the input is:  torch.Size([128, 196, 192])
the shape of the input is:  torch.Size([128, 196, 192])

Validation epoch 0 :  58%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                                                                                   | 18/31 [00:04<00:02,  5.71it/s]
the shape of the input is:  torch.Size([128, 196, 192])
the shape of the input is:  torch.Size([128, 196, 192])
the shape of the input is:  torch.Size([128, 196, 192])
the shape of the input is:  torch.Size([128, 196, 192])
the shape of the input is:  torch.Size([128, 196, 192])
the shape of the input is:  torch.Size([128, 196, 192])
the shape of the input is:  torch.Size([128, 196, 192])
the shape of the input is:  torch.Size([128, 196, 192])
the shape of the input is:  torch.Size([128, 196, 192])
the shape of the input is:  torch.Size([128, 196, 192])

Validation epoch 0 :  97%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌      | 30/31 [00:06<00:00,  5.83it/s]
the shape of the input is:  torch.Size([85, 196, 192])
Saving training state for epoch 0.
[WARNING] Plotting masks is only supported for models with a budget. Skipping...
Freezing all parameters except for those containing any of these words in their names:  ['gate', 'class', 'head', 'threshold', 'budget']
the shape of the input is:  torch.Size([128, 196, 192])
Validation epoch 0 : 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 31/31 [00:06<00:00,  4.96it/s]
Training epoch 1:   3%|█████▍                                                                                                                                                                                                     | 2/74 [00:01<00:59,  1.21it/s]
the shape of the input is:  torch.Size([128, 196, 192])
the shape of the input is:  torch.Size([128, 196, 192])
the shape of the input is:  torch.Size([128, 196, 192])
the shape of the input is:  torch.Size([128, 196, 192])
the shape of the input is:  torch.Size([128, 196, 192])

Training epoch 1:   9%|███████████████████▏                                                                                                                                                                                       | 7/74 [00:03<00:28,  2.31it/s]
the shape of the input is:  torch.Size([128, 196, 192])
the shape of the input is:  torch.Size([128, 196, 192])
the shape of the input is:  torch.Size([128, 196, 192])
the shape of the input is:  torch.Size([128, 196, 192])

Training epoch 1:  16%|████████████████████████████████▊                                                                                                                                                                         | 12/74 [00:05<00:24,  2.52it/s]
the shape of the input is:  torch.Size([128, 196, 192])
the shape of the input is:  torch.Size([128, 196, 192])
the shape of the input is:  torch.Size([128, 196, 192])
the shape of the input is:  torch.Size([128, 196, 192])

Training epoch 1:  23%|██████████████████████████████████████████████▍                                                                                                                                                           | 17/74 [00:07<00:22,  2.55it/s]
the shape of the input is:  torch.Size([128, 196, 192])
the shape of the input is:  torch.Size([128, 196, 192])
the shape of the input is:  torch.Size([128, 196, 192])
the shape of the input is:  torch.Size([128, 196, 192])

Training epoch 1:  30%|████████████████████████████████████████████████████████████                                                                                                                                              | 22/74 [00:09<00:20,  2.56it/s]
the shape of the input is:  torch.Size([128, 196, 192])
the shape of the input is:  torch.Size([128, 196, 192])
the shape of the input is:  torch.Size([128, 196, 192])
the shape of the input is:  torch.Size([128, 196, 192])

Training epoch 1:  36%|█████████████████████████████████████████████████████████████████████████▋                                                                                                                                | 27/74 [00:11<00:18,  2.56it/s]
the shape of the input is:  torch.Size([128, 196, 192])
the shape of the input is:  torch.Size([128, 196, 192])
the shape of the input is:  torch.Size([128, 196, 192])
the shape of the input is:  torch.Size([128, 196, 192])

Training epoch 1:  45%|██████████████████████████████████████████████████████████████████████████████████████████                                                                                                                | 33/74 [00:13<00:16,  2.55it/s]
the shape of the input is:  torch.Size([128, 196, 192])
the shape of the input is:  torch.Size([128, 196, 192])
the shape of the input is:  torch.Size([128, 196, 192])
the shape of the input is:  torch.Size([128, 196, 192])

Training epoch 1:  51%|███████████████████████████████████████████████████████████████████████████████████████████████████████▋                                                                                                  | 38/74 [00:15<00:14,  2.55it/s]
the shape of the input is:  torch.Size([128, 196, 192])
the shape of the input is:  torch.Size([128, 196, 192])
the shape of the input is:  torch.Size([128, 196, 192])
the shape of the input is:  torch.Size([128, 196, 192])

Training epoch 1:  58%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                                                                                    | 43/74 [00:17<00:12,  2.55it/s]
the shape of the input is:  torch.Size([128, 196, 192])
the shape of the input is:  torch.Size([128, 196, 192])
the shape of the input is:  torch.Size([128, 196, 192])
the shape of the input is:  torch.Size([128, 196, 192])
the shape of the input is:  torch.Size([128, 196, 192])

Training epoch 1:  65%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                                                                       | 48/74 [00:19<00:10,  2.55it/s]
the shape of the input is:  torch.Size([128, 196, 192])
the shape of the input is:  torch.Size([128, 196, 192])
the shape of the input is:  torch.Size([128, 196, 192])
the shape of the input is:  torch.Size([128, 196, 192])

Training epoch 1:  72%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                                         | 53/74 [00:21<00:08,  2.56it/s]
the shape of the input is:  torch.Size([128, 196, 192])
the shape of the input is:  torch.Size([128, 196, 192])
the shape of the input is:  torch.Size([128, 196, 192])
the shape of the input is:  torch.Size([128, 196, 192])

Training epoch 1:  78%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                                           | 58/74 [00:23<00:06,  2.56it/s]
the shape of the input is:  torch.Size([128, 196, 192])
the shape of the input is:  torch.Size([128, 196, 192])
the shape of the input is:  torch.Size([128, 196, 192])
the shape of the input is:  torch.Size([128, 196, 192])

Training epoch 1:  85%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                              | 63/74 [00:25<00:04,  2.55it/s]
the shape of the input is:  torch.Size([128, 196, 192])
the shape of the input is:  torch.Size([128, 196, 192])
the shape of the input is:  torch.Size([128, 196, 192])
the shape of the input is:  torch.Size([128, 196, 192])

Training epoch 1:  92%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                | 68/74 [00:27<00:02,  2.55it/s]
the shape of the input is:  torch.Size([128, 196, 192])
the shape of the input is:  torch.Size([128, 196, 192])
the shape of the input is:  torch.Size([128, 196, 192])
the shape of the input is:  torch.Size([128, 196, 192])
Training epoch 1: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 74/74 [00:30<00:00,  2.46it/s]
Training epoch 2:   0%|                                                                                                                                                                                                                   | 0/74 [00:00<?, ?it/s]
Freezing all parameters except for those containing any of these words in their names:  ['gate', 'class', 'head', 'threshold', 'budget']
the shape of the input is:  torch.Size([128, 196, 192])
the shape of the input is:  torch.Size([128, 196, 192])

Training epoch 2:   3%|█████▍                                                                                                                                                                                                     | 2/74 [00:01<00:56,  1.28it/s]
the shape of the input is:  torch.Size([128, 196, 192])
the shape of the input is:  torch.Size([128, 196, 192])
the shape of the input is:  torch.Size([128, 196, 192])
the shape of the input is:  torch.Size([128, 196, 192])

Training epoch 2:   9%|███████████████████▏                                                                                                                                                                                       | 7/74 [00:03<00:28,  2.33it/s]
the shape of the input is:  torch.Size([128, 196, 192])
the shape of the input is:  torch.Size([128, 196, 192])
the shape of the input is:  torch.Size([128, 196, 192])
the shape of the input is:  torch.Size([128, 196, 192])

Training epoch 2:  16%|████████████████████████████████▊                                                                                                                                                                         | 12/74 [00:05<00:24,  2.52it/s]
the shape of the input is:  torch.Size([128, 196, 192])
the shape of the input is:  torch.Size([128, 196, 192])
the shape of the input is:  torch.Size([128, 196, 192])
the shape of the input is:  torch.Size([128, 196, 192])

Training epoch 2:  24%|█████████████████████████████████████████████████▏                                                                                                                                                        | 18/74 [00:07<00:21,  2.55it/s]
the shape of the input is:  torch.Size([128, 196, 192])
the shape of the input is:  torch.Size([128, 196, 192])
the shape of the input is:  torch.Size([128, 196, 192])
the shape of the input is:  torch.Size([128, 196, 192])

Training epoch 2:  31%|██████████████████████████████████████████████████████████████▊                                                                                                                                           | 23/74 [00:09<00:19,  2.55it/s]
the shape of the input is:  torch.Size([128, 196, 192])
the shape of the input is:  torch.Size([128, 196, 192])
the shape of the input is:  torch.Size([128, 196, 192])
the shape of the input is:  torch.Size([128, 196, 192])

Training epoch 2:  38%|████████████████████████████████████████████████████████████████████████████▍                                                                                                                             | 28/74 [00:11<00:18,  2.55it/s]
the shape of the input is:  torch.Size([128, 196, 192])
the shape of the input is:  torch.Size([128, 196, 192])
the shape of the input is:  torch.Size([128, 196, 192])
the shape of the input is:  torch.Size([128, 196, 192])

Training epoch 2:  45%|██████████████████████████████████████████████████████████████████████████████████████████                                                                                                                | 33/74 [00:13<00:16,  2.55it/s]
the shape of the input is:  torch.Size([128, 196, 192])
the shape of the input is:  torch.Size([128, 196, 192])
the shape of the input is:  torch.Size([128, 196, 192])
the shape of the input is:  torch.Size([128, 196, 192])
the shape of the input is:  torch.Size([128, 196, 192])

Training epoch 2:  51%|███████████████████████████████████████████████████████████████████████████████████████████████████████▋                                                                                                  | 38/74 [00:15<00:14,  2.54it/s]
the shape of the input is:  torch.Size([128, 196, 192])
the shape of the input is:  torch.Size([128, 196, 192])
the shape of the input is:  torch.Size([128, 196, 192])
the shape of the input is:  torch.Size([128, 196, 192])

Training epoch 2:  58%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                                                                                    | 43/74 [00:17<00:12,  2.55it/s]
the shape of the input is:  torch.Size([128, 196, 192])
the shape of the input is:  torch.Size([128, 196, 192])
the shape of the input is:  torch.Size([128, 196, 192])
the shape of the input is:  torch.Size([128, 196, 192])

Training epoch 2:  65%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                                                                       | 48/74 [00:19<00:10,  2.55it/s]
the shape of the input is:  torch.Size([128, 196, 192])
the shape of the input is:  torch.Size([128, 196, 192])
the shape of the input is:  torch.Size([128, 196, 192])
the shape of the input is:  torch.Size([128, 196, 192])

Training epoch 2:  72%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                                         | 53/74 [00:21<00:08,  2.54it/s]
the shape of the input is:  torch.Size([128, 196, 192])
the shape of the input is:  torch.Size([128, 196, 192])
the shape of the input is:  torch.Size([128, 196, 192])
the shape of the input is:  torch.Size([128, 196, 192])

Training epoch 2:  80%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                                         | 59/74 [00:24<00:05,  2.55it/s]
the shape of the input is:  torch.Size([128, 196, 192])
the shape of the input is:  torch.Size([128, 196, 192])
the shape of the input is:  torch.Size([128, 196, 192])
the shape of the input is:  torch.Size([128, 196, 192])

Training epoch 2:  86%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                           | 64/74 [00:26<00:03,  2.55it/s]
the shape of the input is:  torch.Size([128, 196, 192])
the shape of the input is:  torch.Size([128, 196, 192])
the shape of the input is:  torch.Size([128, 196, 192])
the shape of the input is:  torch.Size([128, 196, 192])

Training epoch 2:  93%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎             | 69/74 [00:28<00:01,  2.55it/s]
the shape of the input is:  torch.Size([128, 196, 192])
the shape of the input is:  torch.Size([128, 196, 192])
the shape of the input is:  torch.Size([128, 196, 192])
the shape of the input is:  torch.Size([128, 196, 192])
Training epoch 2: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 74/74 [00:29<00:00,  2.47it/s]
Training epoch 3:   0%|                                                                                                                                                                                                                   | 0/74 [00:00<?, ?it/s]
Freezing all parameters except for those containing any of these words in their names:  ['gate', 'class', 'head', 'threshold', 'budget']
the shape of the input is:  torch.Size([128, 196, 192])
the shape of the input is:  torch.Size([128, 196, 192])

Training epoch 3:   4%|████████▏                                                                                                                                                                                                  | 3/74 [00:02<00:42,  1.66it/s]
the shape of the input is:  torch.Size([128, 196, 192])
the shape of the input is:  torch.Size([128, 196, 192])
the shape of the input is:  torch.Size([128, 196, 192])
the shape of the input is:  torch.Size([128, 196, 192])

Training epoch 3:  11%|█████████████████████▉                                                                                                                                                                                     | 8/74 [00:04<00:27,  2.40it/s]
the shape of the input is:  torch.Size([128, 196, 192])
the shape of the input is:  torch.Size([128, 196, 192])
the shape of the input is:  torch.Size([128, 196, 192])
the shape of the input is:  torch.Size([128, 196, 192])

Training epoch 3:  18%|███████████████████████████████████▍                                                                                                                                                                      | 13/74 [00:06<00:24,  2.52it/s]
the shape of the input is:  torch.Size([128, 196, 192])
the shape of the input is:  torch.Size([128, 196, 192])
the shape of the input is:  torch.Size([128, 196, 192])
the shape of the input is:  torch.Size([128, 196, 192])

Training epoch 3:  24%|█████████████████████████████████████████████████▏                                                                                                                                                        | 18/74 [00:07<00:22,  2.54it/s]
the shape of the input is:  torch.Size([128, 196, 192])
the shape of the input is:  torch.Size([128, 196, 192])
the shape of the input is:  torch.Size([128, 196, 192])
the shape of the input is:  torch.Size([128, 196, 192])

Training epoch 3:  31%|██████████████████████████████████████████████████████████████▊                                                                                                                                           | 23/74 [00:09<00:20,  2.53it/s]
the shape of the input is:  torch.Size([128, 196, 192])
the shape of the input is:  torch.Size([128, 196, 192])
the shape of the input is:  torch.Size([128, 196, 192])
the shape of the input is:  torch.Size([128, 196, 192])
the shape of the input is:  torch.Size([128, 196, 192])

Training epoch 3:  38%|████████████████████████████████████████████████████████████████████████████▍                                                                                                                             | 28/74 [00:11<00:18,  2.55it/s]
the shape of the input is:  torch.Size([128, 196, 192])
the shape of the input is:  torch.Size([128, 196, 192])
the shape of the input is:  torch.Size([128, 196, 192])
the shape of the input is:  torch.Size([128, 196, 192])

Training epoch 3:  45%|██████████████████████████████████████████████████████████████████████████████████████████                                                                                                                | 33/74 [00:13<00:16,  2.55it/s]
the shape of the input is:  torch.Size([128, 196, 192])
the shape of the input is:  torch.Size([128, 196, 192])
the shape of the input is:  torch.Size([128, 196, 192])
the shape of the input is:  torch.Size([128, 196, 192])

Training epoch 3:  51%|███████████████████████████████████████████████████████████████████████████████████████████████████████▋                                                                                                  | 38/74 [00:15<00:14,  2.53it/s]
the shape of the input is:  torch.Size([128, 196, 192])
the shape of the input is:  torch.Size([128, 196, 192])
the shape of the input is:  torch.Size([128, 196, 192])
the shape of the input is:  torch.Size([128, 196, 192])

Training epoch 3:  59%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                                                                                  | 44/74 [00:18<00:11,  2.53it/s]
the shape of the input is:  torch.Size([128, 196, 192])
the shape of the input is:  torch.Size([128, 196, 192])
the shape of the input is:  torch.Size([128, 196, 192])
the shape of the input is:  torch.Size([128, 196, 192])

Training epoch 3:  66%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                                                                    | 49/74 [00:20<00:09,  2.54it/s]
the shape of the input is:  torch.Size([128, 196, 192])
the shape of the input is:  torch.Size([128, 196, 192])
the shape of the input is:  torch.Size([128, 196, 192])
the shape of the input is:  torch.Size([128, 196, 192])

Training epoch 3:  73%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                                                      | 54/74 [00:22<00:07,  2.53it/s]
the shape of the input is:  torch.Size([128, 196, 192])
the shape of the input is:  torch.Size([128, 196, 192])
the shape of the input is:  torch.Size([128, 196, 192])
the shape of the input is:  torch.Size([128, 196, 192])

Training epoch 3:  80%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                                         | 59/74 [00:24<00:05,  2.54it/s]
the shape of the input is:  torch.Size([128, 196, 192])
the shape of the input is:  torch.Size([128, 196, 192])
the shape of the input is:  torch.Size([128, 196, 192])
the shape of the input is:  torch.Size([128, 196, 192])

Training epoch 3:  86%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                           | 64/74 [00:26<00:03,  2.54it/s]
the shape of the input is:  torch.Size([128, 196, 192])
the shape of the input is:  torch.Size([128, 196, 192])
the shape of the input is:  torch.Size([128, 196, 192])
the shape of the input is:  torch.Size([128, 196, 192])


Training epoch 3: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 74/74 [00:30<00:00,  2.46it/s]
the shape of the input is:  torch.Size([128, 196, 192])
the shape of the input is:  torch.Size([128, 196, 192])
the shape of the input is:  torch.Size([128, 196, 192])
the shape of the input is:  torch.Size([128, 196, 192])
the shape of the input is:  torch.Size([125, 196, 192])