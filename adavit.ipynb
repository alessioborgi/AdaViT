{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":109264,"sourceType":"datasetVersion","datasetId":56828},{"sourceId":998277,"sourceType":"datasetVersion","datasetId":547506},{"sourceId":2251350,"sourceType":"datasetVersion","datasetId":1354190}],"dockerImageVersionId":30615,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"### 0: IMPORTING LIBRARIES AND SETTING THE SEEDS","metadata":{}},{"cell_type":"code","source":"# Importing necessary libraries\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import DataLoader, random_split\nfrom torchvision import transforms\nfrom torchvision.datasets import ImageFolder\nfrom pathlib import Path\nimport pytorch_lightning as pl\nfrom typing import Tuple\nimport PIL\nfrom PIL import Image\nfrom pytorch_lightning.callbacks.progress import TQDMProgressBar\nimport csv\nfrom torchmetrics.functional import accuracy\nimport numpy as np\nimport torchvision\nfrom torchvision.transforms import ToPILImage\nimport matplotlib.pyplot as plt\nimport numpy as np\nfrom torchvision import transforms\nimport cv2\nfrom torchvision import datasets\nfrom torchmetrics.classification import Accuracy, MulticlassF1Score, MulticlassPrecision, MulticlassRecall\nfrom sklearn.metrics import classification_report\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom torch.utils.data import DataLoader\nfrom torch.utils.data import DataLoader, random_split\nfrom pytorch_lightning.loggers import TensorBoardLogger, CSVLogger\nfrom torch.optim.lr_scheduler import CosineAnnealingLR\nfrom sklearn.utils.class_weight import compute_class_weight\nfrom torch.nn import CrossEntropyLoss\nfrom pytorch_lightning.callbacks import TQDMProgressBar, LearningRateMonitor, ModelCheckpoint\nimport math","metadata":{"execution":{"iopub.status.busy":"2023-12-19T12:29:13.674919Z","iopub.execute_input":"2023-12-19T12:29:13.675410Z","iopub.status.idle":"2023-12-19T12:29:13.685844Z","shell.execute_reply.started":"2023-12-19T12:29:13.675376Z","shell.execute_reply":"2023-12-19T12:29:13.684645Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Fixing random state for reproducibility using NumPy\nrng = np.random.RandomState(31)\n\n# Setting the seed for NumPy to ensure reproducibility\nnp.random.seed(31)\n\n# Setting the seed for PyTorch Lightning to ensure reproducibility\npl.seed_everything(31)\n\n#torch.manual_seed(31)\n#torch.cuda.manual_seed(31)\n#torch.backends.cudnn.deterministic = True","metadata":{"execution":{"iopub.status.busy":"2023-12-19T12:29:13.688150Z","iopub.execute_input":"2023-12-19T12:29:13.689309Z","iopub.status.idle":"2023-12-19T12:29:13.705133Z","shell.execute_reply.started":"2023-12-19T12:29:13.689257Z","shell.execute_reply":"2023-12-19T12:29:13.703697Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 1: DATA INSPECTION","metadata":{}},{"cell_type":"markdown","source":"#### 1.1: CREATION OF THE LABEL DICTIONARY","metadata":{}},{"cell_type":"code","source":"mapping_dict = {}\n\n# Open the file in read mode.\nwith open('/kaggle/input/tiny-imagenet/tiny-imagenet-200/words.txt', 'r') as file:\n    # Read each line from the file.\n    for line in file:\n        # Split the line into tokens based on whitespace.\n        tokens = line.strip().split('\\t')\n        \n        # Check if there are at least two tokens.\n        if len(tokens) >= 2:\n            # Extract the encoded label (left) and actual label (right).\n            encoded_label, actual_label = tokens[0], tokens[1]\n            \n            # Add the mapping to the dictionary.\n            mapping_dict[encoded_label] = actual_label\n\n# Print the mapping dictionary.\n#print(mapping_dict)\n","metadata":{"execution":{"iopub.status.busy":"2023-12-19T12:29:13.706816Z","iopub.execute_input":"2023-12-19T12:29:13.707734Z","iopub.status.idle":"2023-12-19T12:29:13.811508Z","shell.execute_reply.started":"2023-12-19T12:29:13.707667Z","shell.execute_reply":"2023-12-19T12:29:13.810217Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### 1.2: DISPLAYING EXAMPLES OF THE DATASET","metadata":{}},{"cell_type":"code","source":"# Loading the dataset using ImageFolder.\ndataset0 = datasets.ImageFolder(root=\"/kaggle/input/tiny-imagenet/tiny-imagenet-200/train/\", transform=None)\n\n# Extract class names and their counts.\nclass_names = dataset0.classes\nclass_counts = [dataset0.targets.count(i) for i in range(len(class_names))]\nnp.random.seed(31)\n\n# Create a grid of 10 images with labels.\nplt.figure(figsize=(15, 8))\nfor i in range(10):\n    \n    # Randomly select an image and its corresponding label.\n    index = np.random.randint(len(dataset0))\n    image, label = dataset0[index]\n\n    # Display the image with its label\n    plt.subplot(2, 5, i+1)\n    plt.imshow(np.array(image))  # Convert the PIL Image to a numpy array\n    plt.title(f\"Label: {class_names[label]}\")\n    plt.axis('off')\n\nplt.tight_layout()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-12-19T12:29:13.812826Z","iopub.execute_input":"2023-12-19T12:29:13.813186Z","iopub.status.idle":"2023-12-19T12:29:15.729625Z","shell.execute_reply.started":"2023-12-19T12:29:13.813146Z","shell.execute_reply":"2023-12-19T12:29:15.728617Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Assuming you have already loaded the dataset using ImageFolder\ndataset0 = datasets.ImageFolder(root=\"/kaggle/input/tiny-imagenet/tiny-imagenet-200/train/\", transform=None)\n\n# Extract class names and their counts\nclass_names = dataset0.classes\nclass_counts = [dataset0.targets.count(i) for i in range(len(class_names))]\n\nnp.random.seed(31)\n# Create a grid of 10 images with labels\nplt.figure(figsize=(15, 8))\nfor i in range(10):\n    # Randomly select an image and its corresponding label\n    index = np.random.randint(len(dataset0))\n    image, encoded_label = dataset0[index]\n    # Look up the actual label using the mapping dictionary\n    actual_label = mapping_dict.get(class_names[encoded_label], \"Unknown Label\")\n    \n    # Trim the label if it exceeds the maximum length.\n    actual_label_trimmed = actual_label[:15] + '...' if len(actual_label) > 15 else actual_label\n\n    # Display the image with its label.\n    plt.subplot(2, 5, i+1)\n    plt.imshow(np.array(image))  # Convert the PIL Image to a numpy array\n    plt.title(f\"Label: {actual_label_trimmed}\", wrap=True)\n    plt.axis('off')\n\nplt.tight_layout()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-12-19T12:29:15.731685Z","iopub.execute_input":"2023-12-19T12:29:15.732643Z","iopub.status.idle":"2023-12-19T12:29:18.157177Z","shell.execute_reply.started":"2023-12-19T12:29:15.732592Z","shell.execute_reply":"2023-12-19T12:29:18.155842Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class CustomValidationDataset(Dataset):\n    def __init__(self, root, transform=None):\n        \n        self.root = Path(root)\n        self.transform = transform\n        self.image_paths = sorted(list(self.root.glob(\"val_*.JPEG\")))\n        self.labels = self.load_labels()\n\n    def __len__(self):\n        return len(self.image_paths)\n\n    def __getitem__(self, index):\n        image_path = self.image_paths[index]\n        image = Image.open(image_path).convert(\"RGB\")\n\n        if self.transform:\n            image = self.transform(image)\n\n        label = self.labels[image_path.stem]\n\n        return image, label\n\n    def load_labels(self):\n        \n        label_path = \"/kaggle/input/tiny-imagenet/tiny-imagenet-200/val/val_annotations.txt\"\n        labels = {}\n\n        with open(label_path, \"r\") as f:\n            lines = f.readlines()\n\n        for line in lines:\n            parts = line.split(\"\\t\")\n            image_name, label = parts[0], parts[1]\n            labels[image_name] = label\n\n        return labels\n","metadata":{"execution":{"iopub.status.busy":"2023-12-19T12:29:18.158616Z","iopub.execute_input":"2023-12-19T12:29:18.159562Z","iopub.status.idle":"2023-12-19T12:29:18.168580Z","shell.execute_reply.started":"2023-12-19T12:29:18.159522Z","shell.execute_reply":"2023-12-19T12:29:18.167236Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class AViT_DataModule(pl.LightningDataModule):\n    def __init__(self, train_data_dir, val_data_dir, batch_size, num_workers=4):\n        super(HW2_DataModule, self).__init__()\n        self.train_data_dir = train_data_dir\n        self.val_data_dir = val_data_dir\n        self.batch_size = batch_size\n        self.num_workers = num_workers\n\n        self.transform = transforms.Compose([\n            transforms.ToTensor()\n        ])\n\n    def setup(self, stage=None):\n        # Load Train dataset.\n        self.train_dataset = ImageFolder(self.train_data_dir, transform=self.transform)\n\n        # Load Validation dataset.\n        self.val_dataset = CustomValidationDataset(root=self.val_data_dir, transform=self.transform)\n\n    def train_dataloader(self):\n        # Return the DataLoader for the training dataset\n        return DataLoader(self.train_dataset, batch_size=self.batch_size, num_workers=self.num_workers, shuffle=True)\n\n    def val_dataloader(self):\n        # Return the DataLoader for the validation dataset\n        return DataLoader(self.val_dataset, batch_size=self.batch_size, num_workers=self.num_workers)\n","metadata":{"execution":{"iopub.status.busy":"2023-12-19T12:29:18.170821Z","iopub.execute_input":"2023-12-19T12:29:18.172070Z","iopub.status.idle":"2023-12-19T12:29:18.185045Z","shell.execute_reply.started":"2023-12-19T12:29:18.172030Z","shell.execute_reply":"2023-12-19T12:29:18.183439Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"class HW2_DataModule(pl.LightningDataModule): \n    def __init__(self, train_data_dir, test_data_dir, batch_size, num_workers=4, val_split=0.2):\n        \n        super(HW2_DataModule, self).__init__()\n        self.train_data_dir = train_data_dir\n        self.test_data_dir = test_data_dir\n        self.batch_size = batch_size\n        self.num_workers = num_workers\n        self.val_split = val_split\n        \n        self.transform = transforms.Compose([\n            #transforms.Lambda(lambda x: x.crop((12, 12, x.width - 12, x.height - 12))),\n            transforms.ToTensor()\n        ])\n\n    def setup(self, stage=None):\n        # Load Train dataset.\n        self.train_dataset = ImageFolder(self.train_data_dir, transform=self.transform)\n\n        # Load the test dataset with preprocessing\n        #self.test_dataset = ImageFolder(self.test_data_dir, transform=self.transform)\n\n    def train_dataloader(self):\n        \n        # Return the DataLoader for the training dataset\n        return DataLoader(self.train_dataset, batch_size=self.batch_size, num_workers=self.num_workers, shuffle = True)\n\n    def val_dataloader(self):\n        \n        # Return the DataLoader for the validation dataset\n        return DataLoader(self.val_dataset, batch_size=self.batch_size, num_workers=self.num_workers)\n    \n    def test_dataloader(self):\n        # Return the DataLoader for the test dataset\n        return DataLoader(self.test_dataset, batch_size=self.batch_size, num_workers=self.num_workers)\n\n    ","metadata":{"execution":{"iopub.status.busy":"2023-12-19T12:11:19.489801Z","iopub.execute_input":"2023-12-19T12:11:19.490183Z","iopub.status.idle":"2023-12-19T12:11:19.503089Z","shell.execute_reply.started":"2023-12-19T12:11:19.490152Z","shell.execute_reply":"2023-12-19T12:11:19.501727Z"}}},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}