Model Hypeparameters: input_size=(3, 224, 224),n_patches=14,n_blocks=12,n_heads=3,hidden_d=192,output_size=10,batch_size=128,learning_rate=0.0015,weight_decay=0.00015,temp=0.5,class_mlp_ratio=4,vit_mlp_ratio=4
Training Loss,Training Accuracy,Validation Loss,Validation Top-1 Accuracy,Validation Top-3 Accuracy,Validation Top-5 Accuracy,Validation Top-10 Accuracy,Percentage halted tokens layer_0,Percentage halted tokens layer_1,Percentage halted tokens layer_2,Percentage halted tokens layer_3,Percentage halted tokens layer_4,Percentage halted tokens layer_5,Percentage halted tokens layer_6,Percentage halted tokens layer_7,Percentage halted tokens layer_8,Percentage halted tokens layer_9,Percentage halted tokens layer_10,Percentage halted tokens layer_11,Variance halted tokens layer_0,Variance halted tokens layer_1,Variance halted tokens layer_2,Variance halted tokens layer_3,Variance halted tokens layer_4,Variance halted tokens layer_5,Variance halted tokens layer_6,Variance halted tokens layer_7,Variance halted tokens layer_8,Variance halted tokens layer_9,Variance halted tokens layer_10,Variance halted tokens layer_11
4.806642055511475,0.20781899988651276,4.069271087646484,0.31977370381355286,0.6328125,0.7916890978813171,1.0
4.233275413513184,0.33033642172813416,4.2042555809021,0.3595770597457886,0.650727391242981,0.8259024620056152,1.0
3.949847459793091,0.38357460498809814,3.764111042022705,0.4034213423728943,0.7234644293785095,0.8608566522598267,1.0
