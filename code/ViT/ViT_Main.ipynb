{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# (AdaViT) ADAPTIVE VISION TRANSFORMERS\n",
    "\n",
    "### SAPIENZA UNIVESITY of ROME (DEPARTMENT OF COMPUTER, CONTROL AND MANAGEMENT ENGINEEERING)\n",
    "\n",
    "### COURSE IN ARTIFICIAL INTELLIGENCE AND ROBOTICS (ACADEMIC YEAR 2023/2024)\n",
    "\n",
    "### AUTHOR:  **ALESSIO BORGI**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#!kaggle datasets download -d alessioborgi/pico-imagenet-10\n",
    "#!unzip -q pico-imagenet-10.zip\n",
    "#!mv \"pico-imagenet\" dataset\n",
    "\n",
    "\n",
    "#!kaggle datasets download -d alessioborgi/nano-imagenet-30\n",
    "#!unzip -q nano-imagenet-30.zip\n",
    "#!mv \"nano-imagenet\" dataset\n",
    "\n",
    "\n",
    "#!kaggle datasets download -d alessioborgi/tiny-imagenet-200\n",
    "# !unzip -q tiny-imagenet-200.zip\n",
    "# !mv \"tiny-imagenet-200\" dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0: IMPORTING LIBRARIES \\& SETTINGS\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Importing PyTorch-related Libraries.\n",
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torchvision import datasets\n",
    "from torchvision import transforms\n",
    "from torch.nn import CrossEntropyLoss\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torchvision.transforms import ToPILImage\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR,CosineAnnealingWarmRestarts\n",
    "from torchmetrics.classification import Accuracy, MulticlassF1Score, MulticlassPrecision, MulticlassRecall\n",
    "\n",
    "# Importing PyTorch Lightning-Related Libraries.\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.callbacks.progress import TQDMProgressBar\n",
    "from pytorch_lightning.loggers import TensorBoardLogger, CSVLogger\n",
    "from pytorch_lightning.callbacks import TQDMProgressBar, LearningRateMonitor, ModelCheckpoint\n",
    "\n",
    "# Importing General Libraries.\n",
    "import os\n",
    "import csv\n",
    "import PIL\n",
    "import time\n",
    "import math\n",
    "import glob\n",
    "import random\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "from scipy.stats import norm\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import OrderedDict\n",
    "\n",
    "# Importing from Other Files.\n",
    "from Train_Val_Test_Classes import CustomTrainingTinyImagenet, CustomValidationTinyImagenet, CustomTestTinyImagenet\n",
    "from Transformations import ViT_Transformations\n",
    "from Multi_Head_Self_Attention import MHSA\n",
    "from Positional_Embeddings import get_positional_embeddings_RoPE, get_positional_embeddings_SPE, get_positional_embeddings_BERT\n",
    "from Gumbel_Noise import add_gumbel_noise\n",
    "from utils import set_device, seed_everything\n",
    "from Patchifying import make_matches_from_image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1: DATAMODULE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomTrainingTinyImagenet(ImageFolder):\n",
    "\n",
    "    def __init__(self, root, transform=None):\n",
    "        \"\"\"\n",
    "        Custom dataset class for Tiny ImageNet Training data.\n",
    "\n",
    "        Args:\n",
    "        - root (str): Root directory containing the dataset.\n",
    "        - transform (callable, optional): Optional transform to be applied to the Input Image.\n",
    "        \"\"\"\n",
    "        super(CustomTrainingTinyImagenet, self).__init__(root, transform=transform)\n",
    "\n",
    "        # Create mappings between class labels and numerical indices\n",
    "        self.class_to_index = {cls: idx for idx, cls in enumerate(sorted(self.classes))}\n",
    "        self.index_to_class = {idx: cls for cls, idx in self.class_to_index.items()}\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        \"\"\"\n",
    "        Method to retrieve an item from the dataset.\n",
    "\n",
    "        Args:\n",
    "        - index (int): Index of the item to retrieve.\n",
    "\n",
    "        Returns:\n",
    "        - sample (torch.Tensor): Transformed image sample.\n",
    "        - target (int): Numerical index corresponding to the class label.\n",
    "        \"\"\"\n",
    "        # Retrieve the item and its label from the Dataset.\n",
    "        path, target = self.samples[index]\n",
    "\n",
    "        # Load the image using the default loader.\n",
    "        sample = self.loader(path)\n",
    "\n",
    "        # Apply the specified transformations, if any.\n",
    "        if self.transform is not None:\n",
    "            sample = self.transform(sample)\n",
    "\n",
    "        # Adjust the directory depth to get the target label.\n",
    "        target_str = os.path.basename(os.path.dirname(os.path.dirname(path)))\n",
    "\n",
    "        # Convert string label to numerical index using the mapping.\n",
    "        target = self.class_to_index[target_str]\n",
    "\n",
    "        return sample, target\n",
    "\n",
    "    def get_class_from_index(self, index):\n",
    "        \"\"\"\n",
    "        Method to retrieve the class label from a numerical index.\n",
    "\n",
    "        Args:\n",
    "        - index (int): Numerical index corresponding to the class label.\n",
    "\n",
    "        Returns:\n",
    "        - class_label (str): Class label corresponding to the numerical index.\n",
    "        \"\"\"\n",
    "\n",
    "        return self.index_to_class[index]\n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    "class CustomValidationTinyImagenet(pl.LightningDataModule):\n",
    "\n",
    "    def __init__(self, root, transform=None):\n",
    "        \"\"\"\n",
    "        Custom data module for Tiny ImageNet Validation data.\n",
    "\n",
    "        Args:\n",
    "        - root (str): Root directory containing the dataset.\n",
    "        - transform (callable, optional): Optional transform to be applied to the Input Image.\n",
    "        \"\"\"\n",
    "        self.root = Path(root)\n",
    "        self.transform = transform\n",
    "\n",
    "        # Load and preprocess labels\n",
    "        self.labels = self.load_labels()\n",
    "        self.label_to_index = {label: idx for idx, label in enumerate(sorted(set(self.labels.values())))}\n",
    "        self.index_to_label = {idx: label for label, idx in self.label_to_index.items()}\n",
    "\n",
    "    def load_labels(self):\n",
    "        \"\"\"\n",
    "        Method to load and Pre-Process Labels from the Validation Dataset.\n",
    "\n",
    "        Returns:\n",
    "        - labels (dict): Dictionary mapping image names to labels.\n",
    "        \"\"\"\n",
    "        label_path = \"./dataset/pico-imagenet-10/val/val_annotations.txt\"\n",
    "        labels = {}\n",
    "\n",
    "        with open(label_path, \"r\") as f:\n",
    "            lines = f.readlines()\n",
    "\n",
    "        for i,line in enumerate(lines):\n",
    "            if i == 0:\n",
    "                parts = line.split(\"\\t\")\n",
    "                image_name, label = parts[0], parts[1]\n",
    "                labels['val_0.JPEG'] = label\n",
    "            else:\n",
    "                parts = line.split(\"\\t\")\n",
    "                image_name, label = parts[0], parts[1]\n",
    "                labels[image_name] = label\n",
    "\n",
    "        return labels\n",
    "    def __len__(self):\n",
    "        \"\"\"\n",
    "        Method to get the length of the dataset.\n",
    "\n",
    "        Returns:\n",
    "        - length (int): Number of items in the dataset.\n",
    "        \"\"\"\n",
    "        return len(self.labels)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        \"\"\"\n",
    "        Method to retrieve an item from the dataset.\n",
    "\n",
    "        Args:\n",
    "        - index (int): Index of the item to retrieve.\n",
    "\n",
    "        Returns:\n",
    "        - image (torch.Tensor): Transformed image sample.\n",
    "        - label (int): Numerical index corresponding to the class label.\n",
    "        \"\"\"\n",
    "        image_name = f\"val_{index}.JPEG\"\n",
    "        image_path = self.root / image_name\n",
    "\n",
    "        # Open the image using PIL and convert to RGB.\n",
    "        image = Image.open(image_path).convert(\"RGB\")\n",
    "\n",
    "        # Apply the specified transformations, if any.\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        # Use the get method to handle cases where the key is not present.\n",
    "        label_str = self.labels.get(image_name, 'Label not found')\n",
    "\n",
    "        # Convert string label to numerical index using the mapping.\n",
    "        label = self.label_to_index[label_str]\n",
    "\n",
    "        return image, label\n",
    "\n",
    "    def get_label_from_index(self, index):\n",
    "        \"\"\"\n",
    "        Method to retrieve the class label from a numerical index.\n",
    "\n",
    "        Args:\n",
    "        - index (int): Numerical index corresponding to the class label.\n",
    "\n",
    "        Returns:\n",
    "        - class_label (str): Class label corresponding to the numerical index.\n",
    "        \"\"\"\n",
    "        return self.index_to_label[index]\n",
    "    \n",
    "    \n",
    "\n",
    "class CustomTestTinyImagenet(pl.LightningDataModule):\n",
    "\n",
    "    def __init__(self, root, transform=None):\n",
    "        \"\"\"\n",
    "        Custom dataset class for Tiny ImageNet Test data.\n",
    "\n",
    "        Args:\n",
    "        - root (str): Root directory containing the dataset.\n",
    "        - transform (callable, optional): Optional transform to be applied to the Input Image.\n",
    "        \"\"\"\n",
    "        self.root = root\n",
    "        self.transform = transform\n",
    "        self.image_paths = self._get_image_paths()\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"\n",
    "        Method to get the total number of items in the dataset.\n",
    "\n",
    "        Returns:\n",
    "        - int: Total number of items in the dataset.\n",
    "        \"\"\"\n",
    "        return len(self.image_paths)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        \"\"\"\n",
    "        Method to retrieve an item from the dataset.\n",
    "\n",
    "        Args:\n",
    "        - index (int): Index of the item to retrieve.\n",
    "\n",
    "        Returns:\n",
    "        - sample (torch.Tensor): Transformed image sample.\n",
    "        - filename (str): Filename of the image.\n",
    "        \"\"\"\n",
    "        # Get the image path based on the index.\n",
    "        image_path = self.image_paths[index]\n",
    "\n",
    "        # Load the image using the default loader.\n",
    "        sample = Image.open(image_path)\n",
    "\n",
    "        # Apply the specified transformations, if any.\n",
    "        if self.transform is not None:\n",
    "            sample = self.transform(sample)\n",
    "\n",
    "        # Extract the filename from the image path.\n",
    "        filename = os.path.basename(image_path)\n",
    "\n",
    "        # Return a tuple containing the sample and filename.\n",
    "        return sample, filename\n",
    "\n",
    "    def _get_image_paths(self):\n",
    "        \"\"\"\n",
    "        Helper method to get the paths of all images in the test dataset.\n",
    "\n",
    "        Returns:\n",
    "        - list: List of image paths.\n",
    "        \"\"\"\n",
    "        image_paths = [os.path.join(self.root, filename) for filename in os.listdir(self.root)]\n",
    "        return image_paths\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class ViT_DataModule(pl.LightningDataModule):\n",
    "\n",
    "    def __init__(self, train_data_dir, val_data_dir, test_data_dir, batch_size, num_workers=4):\n",
    "        \"\"\"\n",
    "        Custom data module for AViT model training and validation.\n",
    "\n",
    "        Args:\n",
    "        - train_data_dir (str): Directory path for the training dataset.\n",
    "        - val_data_dir (str): Directory path for the validation dataset.\n",
    "        - batch_size (int): Batch size for training and validation DataLoader.\n",
    "        - num_workers (int, optional): Number of workers for DataLoader (default is 4).\n",
    "        \"\"\"\n",
    "        super(ViT_DataModule, self).__init__()\n",
    "        self.train_data_dir = train_data_dir\n",
    "        self.val_data_dir = val_data_dir\n",
    "        self.test_data_dir = test_data_dir\n",
    "        self.batch_size = batch_size\n",
    "        self.batch_size_test = 5\n",
    "        self.num_workers = num_workers\n",
    "\n",
    "        # Use AdaViT transformations for data augmentation\n",
    "        self.transform = ViT_Transformations()\n",
    "\n",
    "    def setup(self, stage=None):\n",
    "        \"\"\"\n",
    "        Method to load and configure datasets for Training and Validation.\n",
    "\n",
    "        Args:\n",
    "        - stage (str, optional): 'fit' for Training and 'test' for Validation (default is None).\n",
    "        \"\"\"\n",
    "        # Load Train dataset using CustomTrainingTinyImagenet with the new directory structure.\n",
    "        self.train_dataset = CustomTrainingTinyImagenet(self.train_data_dir, transform=self.transform)\n",
    "\n",
    "        # Load Validation dataset.\n",
    "        self.val_dataset = CustomValidationTinyImagenet(self.val_data_dir, transform=self.transform)\n",
    "\n",
    "        # Load Test dataset.\n",
    "        self.test_dataset = CustomTestTinyImagenet(self.test_data_dir, transform=self.transform)\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        \"\"\"\n",
    "        Method to return the DataLoader for the Training Dataset.\n",
    "\n",
    "        Returns:\n",
    "        - train_dataloader (DataLoader): DataLoader for Training.\n",
    "        \"\"\"\n",
    "        return DataLoader(self.train_dataset, batch_size=self.batch_size, num_workers=self.num_workers, shuffle=True)\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        \"\"\"\n",
    "        Method to return the DataLoader for the Validation Dataset.\n",
    "\n",
    "        Returns:\n",
    "        - val_dataloader (DataLoader): DataLoader for Validation.\n",
    "        \"\"\"\n",
    "        return DataLoader(self.val_dataset, batch_size=self.batch_size, num_workers=self.num_workers)\n",
    "\n",
    "    def test_dataloader(self):\n",
    "        \"\"\"\n",
    "        Method to return the DataLoader for the Test Dataset.\n",
    "\n",
    "        Returns:\n",
    "        - test_dataloader (DataLoader): DataLoader for Test Set.\n",
    "        \"\"\"\n",
    "        return DataLoader(self.test_dataset, batch_size=self.batch_size_test, num_workers=self.num_workers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2: VIT-BLOCK "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ViT_Block_Layer_Norm(nn.Module):\n",
    "    def __init__(self, hidden_d, n_heads, mlp_ratio=10):\n",
    "        super(ViT_Block_Layer_Norm, self).__init__()\n",
    "        \n",
    "        self.hidden_d = hidden_d\n",
    "        self.n_heads = n_heads\n",
    "\n",
    "        self.norm1 = nn.LayerNorm(hidden_d)\n",
    "        self.mhsa = MHSA(hidden_d, n_heads)\n",
    "        self.norm2 = nn.LayerNorm(hidden_d)\n",
    "        self.mlp = nn.Sequential(\n",
    "            nn.Linear(hidden_d, mlp_ratio * hidden_d),\n",
    "            nn.GELU(),\n",
    "            nn.Linear(mlp_ratio * hidden_d, hidden_d),\n",
    "        )\n",
    "        \n",
    "        # Initialize weights.\n",
    "        self.initialize_weights_block()\n",
    "\n",
    "    def forward(self, x):\n",
    "        \n",
    "        out = x + self.mhsa(self.norm1(x))\n",
    "        out = out + self.mlp(self.norm2(out))\n",
    "        return out\n",
    "    \n",
    "    def initialize_weights_block(self):\n",
    "        \n",
    "        # Initialize weights for linear layers in mlp.\n",
    "        for layer in self.mlp:\n",
    "            if isinstance(layer, nn.Linear):\n",
    "                nn.init.xavier_uniform_(layer.weight)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3: VIT DEFINITION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class Vision_Transformer(nn.Module):\n",
    "\n",
    "    def __init__(self, chw, batch_size, n_patches, n_blocks, hidden_d, n_heads, out_d, lr, nepochs, warmup_epochs, wd, temp, cmlp_ratio, vmlp_ratio):\n",
    "        \"\"\"\n",
    "        Initialize the Vision_Transformer model.\n",
    "\n",
    "        Parameters:\n",
    "        - input_d (int): Dimension of the input.\n",
    "        - n_patches (int): Number of patches.\n",
    "        - n_blocks (int): Number of transformer blocks.\n",
    "        - hidden_d (int): Dimension of the hidden layer.\n",
    "        - n_heads (int): Number of attention heads.\n",
    "        - out_d (int): Output dimension.\n",
    "        - lr (float): Learning rate.\n",
    "        - wd (float): Weight decay.\n",
    "        - temp (float): Temperature scaling.\n",
    "        - cmlp_ratio (int): Ratio for the classification MLP.\n",
    "        - vmlp_ratio (int): Ratio for the ViT MLP.\n",
    "        \"\"\"\n",
    "\n",
    "        # Super Constructor.\n",
    "        super(Vision_Transformer, self).__init__()\n",
    "\n",
    "        # Model Attributes.\n",
    "        self.chw = chw # ( C , H , W )\n",
    "        self.n_patches = n_patches\n",
    "        self.n_blocks = n_blocks\n",
    "        self.n_heads = n_heads\n",
    "        self.hidden_d = hidden_d\n",
    "        self.class_mlp_ratio = cmlp_ratio\n",
    "        self.vit_mlp_ratio = vmlp_ratio\n",
    "\n",
    "    \n",
    "        # Input and Patches Sizes.\n",
    "        assert chw[1] % n_patches == 0, \"Input shape not entirely divisible by number of patches\"\n",
    "        assert chw[2] % n_patches == 0, \"Input shape not entirely divisible by number of patches\"\n",
    "        self.patch_size = (chw[1] / n_patches, chw[2] / n_patches)\n",
    "\n",
    "        # 1) Linear Mapper.\n",
    "        self.input_d = int(chw[0] * self.patch_size[0] * self.patch_size[1])\n",
    "        self.linear_mapper = nn.Linear(self.input_d, self.hidden_d)\n",
    "\n",
    "        # 2) Learnable Classification Token.\n",
    "        self.class_token = nn.Parameter(torch.rand(1, self.hidden_d))\n",
    "\n",
    "        # 3) Positional Embedding.\n",
    "        #self.register_buffer('positional_embeddings', get_positional_embeddings_SPE(n_patches ** 2 + 1, self.hidden_d), persistent=False)\n",
    "        self.register_buffer('positional_embeddings', get_positional_embeddings_RoPE(n_patches ** 2 + 1, self.hidden_d), persistent=False)\n",
    "\n",
    "        # 4) Transformer Encoder Blocks.\n",
    "        # Select one of the following blocks.\n",
    "        # 4.1) Transformer Block with Layer Normalization.\n",
    "        self.blocks = nn.ModuleList([ViT_Block_Layer_Norm(self.hidden_d, self.n_heads,self.vit_mlp_ratio) for _ in range(self.n_blocks)])\n",
    "\n",
    "        # 5) Classification MLP.\n",
    "        self.mlp = nn.Sequential(\n",
    "          nn.Linear(self.hidden_d, class_mlp_ratio * hidden_d),\n",
    "          nn.GELU(),\n",
    "          nn.Linear(class_mlp_ratio * hidden_d, out_d),\n",
    "        )\n",
    "\n",
    "        # Initialize weights.\n",
    "        self.initialize_weights()\n",
    "\n",
    "    def forward(self, images):\n",
    "        \"\"\"\n",
    "        Forward pass of the Vision_Transformer model.\n",
    "\n",
    "        Parameters:\n",
    "        - images (torch.Tensor): Input images tensor.\n",
    "\n",
    "        Returns:\n",
    "        torch.Tensor: Output tensor.\n",
    "        \"\"\"\n",
    "\n",
    "        # Dividing Images into Patches.\n",
    "        n, c, h, w = images.shape\n",
    "        patches = make_matches_from_image(images, self.n_patches).to(self.positional_embeddings.device)\n",
    "\n",
    "        # Running Linear Layer Tokenization.\n",
    "        # Map the Vector corresponding to each patch to the Hidden Size Dimension.\n",
    "        tokens = self.linear_mapper(patches)\n",
    "\n",
    "        # Adding Classification Token to the Tokens.\n",
    "        tokens = torch.cat((self.class_token.expand(n, 1, -1), tokens), dim=1).to(\"cuda\")\n",
    "\n",
    "        # Adding Positional Embedding.\n",
    "        out = tokens + self.positional_embeddings.repeat(n, 1, 1).to(\"cuda\")\n",
    "\n",
    "        # Transformer Blocks.\n",
    "        for block in self.blocks:\n",
    "            \n",
    "            out = block(out)\n",
    "            \n",
    "        out = out[:, 0]\n",
    "        \n",
    "        return self.mlp(out)\n",
    "\n",
    "\n",
    "    def initialize_weights(self):\n",
    "        \"\"\"\n",
    "        Initialize weights for linear layers, embeddings, etc.\n",
    "        \"\"\"\n",
    "\n",
    "        # Initialize Weights for Linear Layers, Embeddings, etc.\n",
    "        nn.init.xavier_uniform_(self.linear_mapper.weight)\n",
    "        nn.init.normal_(self.class_token.data)\n",
    "\n",
    "        # Initialize Weights for Classification MLP.\n",
    "        nn.init.xavier_uniform_(self.mlp[0].weight)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class ViT(Vision_Transformer, pl.LightningModule):\n",
    "\n",
    "    def __init__(self, input_d, batch_size, n_patches, n_blocks, hidden_d, n_heads, out_d, lr, nepochs, warmup_epochs, wd, temp, cmlp_ratio, vmlp_ratio):\n",
    "        \"\"\"\n",
    "        Initialize the ViT, a LightningModule using Vision_Transformer as a base.\n",
    "\n",
    "        Parameters:\n",
    "        - input_d (int): Dimension of the input.\n",
    "        - n_patches (int): Number of patches.\n",
    "        - n_blocks (int): Number of transformer blocks.\n",
    "        - hidden_d (int): Dimension of the hidden layer.\n",
    "        - n_heads (int): Number of attention heads.\n",
    "        - out_d (int): Output dimension.\n",
    "        - lr (float): Learning rate.\n",
    "        - wd (float): Weight decay.\n",
    "        - temp (float): Temperature scaling.\n",
    "        - cmlp_ratio (int): Ratio for the classification MLP.\n",
    "        - vmlp_ratio (int): Ratio for the ViT MLP.\n",
    "        \"\"\"\n",
    "        super(ViT, self).__init__(input_d, batch_size, n_patches, n_blocks, hidden_d, n_heads, out_d, lr, nepochs, warmup_epochs, wd, temp, cmlp_ratio, vmlp_ratio)\n",
    "        # Optimizer hyperparams.\n",
    "        self.learning_rate = lr\n",
    "        self.nepochs = nepochs\n",
    "        self.weight_decay = wd\n",
    "        self.warmup_epochs = warmup_epochs\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "        # Definition of the Cross Entropy Loss.\n",
    "        self.loss = CrossEntropyLoss()\n",
    "        self.temperature = temp\n",
    "\n",
    "        # Definition of Accuracies, F1Score, Precision, and Recall Metrics.\n",
    "        self.acc_top1 = Accuracy(task=\"multiclass\", num_classes=out_d)\n",
    "        self.acc_top3 = Accuracy(task=\"multiclass\", num_classes=out_d, top_k=3)\n",
    "        self.acc_top5 = Accuracy(task=\"multiclass\", num_classes=out_d, top_k=5)\n",
    "        self.acc_top10 = Accuracy(task=\"multiclass\", num_classes=out_d, top_k=10)\n",
    "        self.f1score = MulticlassF1Score(num_classes=out_d, average='macro')\n",
    "        self.precision = MulticlassPrecision(num_classes=out_d, average='macro')\n",
    "        self.recall = MulticlassRecall(num_classes=out_d, average='macro')\n",
    "\n",
    "        # Definition of lists to be used in the \"on_ ... _epoch_end\" functions.\n",
    "        self.training_step_outputs = []\n",
    "        self.validation_step_outputs = []\n",
    "        self.test_step_outputs = []\n",
    "\n",
    "        #list of train and validation per epochs performance\n",
    "        self.train_loss=[]\n",
    "        self.train_acc=[]\n",
    "        self.val_loss=[]\n",
    "        self.val_acc1=[]\n",
    "        self.val_acc3=[]\n",
    "        self.val_acc5=[]\n",
    "        self.val_acc10=[]\n",
    "        self.perc=[]\n",
    "        self.var=[]\n",
    "\n",
    "    def _step(self, batch):\n",
    "        \"\"\"\n",
    "        Common computation of the metrics among Training, Validation, and Test Set.\n",
    "\n",
    "        Parameters:\n",
    "        - batch (tuple): Input batch tuple.\n",
    "\n",
    "        Returns:\n",
    "        tuple: Tuple containing loss and various metrics.\n",
    "        \"\"\"\n",
    "        x, y = batch\n",
    "        # Compute the Logits.\n",
    "        preds = self(x)\n",
    "        # Scale the logits using a Temperature Scaling and add Gumbel Noise, s.t. you obtain Gumbel Softmax then.\n",
    "        preds_scaled = add_gumbel_noise(preds) / self.temperature\n",
    "        loss = self.loss(preds_scaled, y) \n",
    "        acc1 = self.acc_top1(preds, y)\n",
    "        acc3 = self.acc_top3(preds, y)\n",
    "        acc5 = self.acc_top5(preds, y)\n",
    "        acc10 = self.acc_top10(preds, y)\n",
    "        f1score = self.f1score(preds, y)\n",
    "        precision = self.precision(preds, y)\n",
    "        recall = self.recall(preds, y)\n",
    "\n",
    "        return loss, acc1, acc3, acc5, acc10, f1score, precision, recall\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        \"\"\"\n",
    "        Training step function.\n",
    "\n",
    "        Parameters:\n",
    "        - batch (tuple): Input batch tuple.\n",
    "        - batch_idx (int): Batch index.\n",
    "\n",
    "        Returns:\n",
    "        torch.Tensor: Training loss.\n",
    "        \"\"\"\n",
    "        # Compute the Training Loss and Accuracy.\n",
    "        loss, acc, _, _, _, _, _, _ = self._step(batch)\n",
    "\n",
    "        # Create a Dictionary to represent the output of the Training step.\n",
    "        training_step_output = {\n",
    "            \"train_loss\": loss.item(),\n",
    "            \"train_acc\": acc.item()\n",
    "        }\n",
    "\n",
    "        # Append the dictionary to the list.\n",
    "        self.training_step_outputs.append(training_step_output)\n",
    "\n",
    "        # Perform logging.\n",
    "        self.log(\"train_loss\", loss, on_step=True, on_epoch=True, prog_bar=True, logger=True)\n",
    "        self.log(\"train_acc\", acc, on_step=True, on_epoch=True, prog_bar=True, logger=True)\n",
    "\n",
    "        return loss\n",
    "\n",
    "    def on_train_epoch_end(self):\n",
    "        \"\"\"\n",
    "        Method called at the end of the training epoch.\n",
    "        Returns:\n",
    "        None\n",
    "        \"\"\"\n",
    "        # Calculate the Mean Loss and Accuracy from the list of dictionaries.\n",
    "        loss_tot = torch.tensor([item[\"train_loss\"] for item in self.training_step_outputs]).mean().to(\"cuda\")\n",
    "        acc_tot = torch.tensor([item[\"train_acc\"] for item in self.training_step_outputs]).mean().to(\"cuda\")\n",
    "\n",
    "        # Log the mean values.\n",
    "        self.log(\"train_loss\", loss_tot)\n",
    "        self.log(\"train_acc\", acc_tot)\n",
    "\n",
    "        # Print messages.\n",
    "        message_loss = f'Epoch {self.current_epoch} Training Loss -> {loss_tot}'\n",
    "        message_accuracy = f'      Training Accuracy -> {acc_tot}'\n",
    "        print(message_loss + message_accuracy)\n",
    "\n",
    "        # Clear the list to free memory.\n",
    "        self.training_step_outputs.clear()\n",
    "\n",
    "        #updating training performance lists\n",
    "        self.train_loss.append(loss_tot.item())\n",
    "        self.train_acc.append(acc_tot.item())\n",
    "\n",
    "\n",
    "        #updating csv logs file\n",
    "        new_row=str(self.train_loss[-1])+\",\"+str(self.train_acc[-1])+\",\"+str(self.val_loss[-1])+\",\"+str(self.val_acc1[-1])+\",\"+str(self.val_acc3[-1])+\",\"+str(self.val_acc5[-1])+\",\"+str(self.val_acc10[-1])\n",
    "        with open(\"./results/logs.csv\",'a',newline='') as file:\n",
    "            #writing row\n",
    "            file.write(new_row+\"\\n\")\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        \"\"\"\n",
    "        Validation step function.\n",
    "\n",
    "        Parameters:\n",
    "        - batch (tuple): Input batch tuple.\n",
    "        - batch_idx (int): Batch index.\n",
    "\n",
    "        Returns:\n",
    "        None\n",
    "        \"\"\"\n",
    "        # Compute the Validation Loss and Accuracy.\n",
    "        loss, acc1, acc3, acc5, acc10, _, _, _ = self._step(batch)\n",
    "\n",
    "        # Create a Dictionary to represent the output of the validation step.\n",
    "        validation_step_output = {\n",
    "            \"val_loss\": loss.item(),\n",
    "            \"val_acc\": acc1.item(),\n",
    "            \"val_acc_3\": acc3.item(),\n",
    "            \"val_acc_5\": acc5.item(),\n",
    "            \"val_acc_10\": acc10.item(),\n",
    "        }\n",
    "\n",
    "        # Append the dictionary to the list.\n",
    "        self.validation_step_outputs.append(validation_step_output)\n",
    "\n",
    "        # Perform logging.\n",
    "        self.log(\"val_loss\", loss, on_epoch=True, prog_bar=True, logger=True)\n",
    "        self.log(\"val_acc\", acc1, on_epoch=True, prog_bar=True, logger=True)\n",
    "        self.log(\"val_acc_3\", acc3, on_epoch=True, prog_bar=True, logger=True)\n",
    "        self.log(\"val_acc_5\", acc5, on_epoch=True, prog_bar=True, logger=True)\n",
    "        self.log(\"val_acc_10\", acc10, on_epoch=True, prog_bar=True, logger=True)\n",
    "\n",
    "    def on_validation_epoch_end(self):\n",
    "        \"\"\"\n",
    "        Method called at the end of the validation epoch.\n",
    "\n",
    "        Returns:\n",
    "        None\n",
    "        \"\"\"\n",
    "        # Calculate the Mean Loss and Accuracy from the list of dictionaries.\n",
    "        loss_tot = torch.tensor([item[\"val_loss\"] for item in self.validation_step_outputs]).mean().to(\"cuda\")\n",
    "        acc_tot = torch.tensor([item[\"val_acc\"] for item in self.validation_step_outputs]).mean().to(\"cuda\")\n",
    "        acc_tot_3 = torch.tensor([item[\"val_acc_3\"] for item in self.validation_step_outputs]).mean().to(\"cuda\")\n",
    "        acc_tot_5 = torch.tensor([item[\"val_acc_5\"] for item in self.validation_step_outputs]).mean().to(\"cuda\")\n",
    "        acc_tot_10 = torch.tensor([item[\"val_acc_10\"] for item in self.validation_step_outputs]).mean().to(\"cuda\")\n",
    "\n",
    "        # Log the mean values.\n",
    "        self.log(\"val_loss\", loss_tot)\n",
    "        self.log(\"val_acc\", acc_tot)\n",
    "        self.log(\"val_acc_3\", acc_tot_3)\n",
    "        self.log(\"val_acc_5\", acc_tot_5)\n",
    "        self.log(\"val_acc_10\", acc_tot_10)\n",
    "\n",
    "        # Print messages.\n",
    "        message_loss = f'Epoch {self.current_epoch} Validation Loss -> {loss_tot}'\n",
    "        message_accuracy = f'      Validation Accuracy -> {acc_tot}'\n",
    "        message_accuracy_3 = f'      Validation Accuracy Top-3 -> {acc_tot_3}'\n",
    "        message_accuracy_5 = f'      Validation Accuracy Top-5-> {acc_tot_5}'\n",
    "        message_accuracy_10 = f'      Validation Accuracy Top-10-> {acc_tot_10}'\n",
    "        print(message_loss + message_accuracy + message_accuracy_3 + message_accuracy_5 + message_accuracy_10)\n",
    "\n",
    "        # Clear the list to free memory.\n",
    "        self.validation_step_outputs.clear()\n",
    "\n",
    "        #updating validation performance lists\n",
    "        self.val_loss.append(loss_tot.item())\n",
    "        self.val_acc1.append(acc_tot.item())\n",
    "        self.val_acc3.append(acc_tot_3.item())\n",
    "        self.val_acc5.append(acc_tot_5.item())\n",
    "        self.val_acc10.append(acc_tot_10.item())\n",
    "\n",
    "    def test_step(self, batch, batch_idx):\n",
    "        \"\"\"\n",
    "        Test step function.\n",
    "\n",
    "        Parameters:\n",
    "        - batch (tuple): Input batch tuple.\n",
    "        - batch_idx (int): Batch index.\n",
    "\n",
    "        Returns:\n",
    "        torch.Tensor: Model predictions.\n",
    "        \"\"\"\n",
    "        x = batch\n",
    "        # Compute the Logits.\n",
    "        preds = self(x)\n",
    "        print(\"The prediction is: \", preds)\n",
    "        return preds\n",
    "\n",
    "    def on_test_epoch_end(self):\n",
    "        \"\"\"\n",
    "        Method called at the end of the test epoch.\n",
    "\n",
    "        Returns:\n",
    "        None\n",
    "        \"\"\"\n",
    "        print(\"Test Epoch Complete.\")\n",
    "\n",
    "    def predict(self, input_image):\n",
    "        \"\"\"\n",
    "        Method called at Inference Time.\n",
    "\n",
    "        Returns:\n",
    "        predicted_labels: prediction over the labels.\n",
    "        \"\"\"\n",
    "\n",
    "        with torch.no_grad():\n",
    "\n",
    "            preds = self(input_image)\n",
    "\n",
    "            # Scale the logits using a Temperature Scaling.\n",
    "            preds_scaled = F.log_softmax(preds / self.temperature, dim=1)\n",
    "\n",
    "            # Get the predicted class labels.\n",
    "            predicted_labels = torch.argmax(preds_scaled, dim=1).cpu().numpy()\n",
    "\n",
    "            return predicted_labels\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        \"\"\"\n",
    "        Configure the optimizer.\n",
    "\n",
    "        Returns:\n",
    "        torch.optim.Optimizer: The optimizer.\n",
    "        \"\"\"\n",
    "        # Configure the Adam Optimizer.\n",
    "        optimizer = optim.Adam(self.parameters(), lr=self.learning_rate, weight_decay=self.weight_decay)\n",
    "        scheduler = CosineAnnealingWarmRestarts(optimizer, T_0=10, T_mult=1, eta_min=0.001)\n",
    "        #scheduler = CosineAnnealingWarmRestarts(optimizer, T_0=10, T_mult=1, eta_min=0.001)\n",
    "        #optimizer, scheduler = get_optimizer_scheduler(\n",
    "        #                                               model,\n",
    "        #                                               lr=self.learning_rate,\n",
    "        #                                               warmup_epochs=self.warmup_epochs,\n",
    "        #                                               num_epochs=self.nepochs,\n",
    "        #                                               weight_decay=self.weight_decay,\n",
    "        #                                               batch_size=self.batch_size\n",
    "        #                                               )\n",
    "\n",
    "        #return optimizer\n",
    "        return {'optimizer': optimizer, 'lr_scheduler': scheduler}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4: CALLBACK DEFINITION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checkpoint CallBack Definition.\n",
    "my_checkpoint_call = ModelCheckpoint(\n",
    "    dirpath=\"./checkpoints/\",\n",
    "    filename=\"Best_Model\",\n",
    "    monitor=\"val_acc\",\n",
    "    mode=\"max\",\n",
    "    save_top_k=1,\n",
    "    save_last=True\n",
    ")\n",
    "\n",
    "# Learning Rate CallBack Definition.\n",
    "my_lr_monitor_call = LearningRateMonitor(logging_interval=\"epoch\")\n",
    "\n",
    "# Early Stopping CallBack Definition.\n",
    "my_early_stopping_call = pl.callbacks.EarlyStopping(monitor=\"val_loss\", patience=50, mode=\"min\", min_delta=0.001)\n",
    "\n",
    "# Progress Bar CallBack Definition.\n",
    "my_progress_bar_call = TQDMProgressBar(refresh_rate=10)\n",
    "\n",
    "# TensorBoardLogger CallBack Definition.\n",
    "#tb_logger = TensorBoardLogger(save_dir=\"./results/logs/\", name=\"ViT\")\n",
    "\n",
    "# CSV CallBack Definition.\n",
    "csv_logger = CSVLogger(\"./results/logs/\", name=\"ViT\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5: MODEL HYPERPAMETERS \\& MODEL INSTANTIATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Instantiate the Adaptive Vision Transformer Model.\n",
    "# Model Hyperparameters-\n",
    "blocks=12\n",
    "heads=3\n",
    "classes=10\n",
    "hidden_dim=192\n",
    "batch=64\n",
    "\n",
    "learning_rate=1.5e-3\n",
    "weight_decay=1.5e-4\n",
    "temperature=0.5\n",
    "class_mlp_ratio=4\n",
    "vit_mlp_ratio=4\n",
    "input_size=(3,224, 224)\n",
    "patches=14\n",
    "\n",
    "number_epochs = 200\n",
    "warmup_epochs = 5\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Halting Hyperparameters.\n",
    "gamma = 5\n",
    "beta = -10\n",
    "alpha_ponder = 5e-4\n",
    "alpha_distribution = 0.1\n",
    "epsilon = 0.01\n",
    "expected_stop_depth=2\n",
    "b_laplace=2 #Set it to \"None\" if not using laplace_distribution\n",
    "\n",
    "model = ViT(input_d = input_size,\n",
    "            batch_size=batch,\n",
    "            n_patches = patches,\n",
    "            n_blocks = blocks,\n",
    "            hidden_d = hidden_dim,\n",
    "            n_heads = heads,\n",
    "            out_d = classes,\n",
    "            lr = learning_rate,\n",
    "            nepochs = number_epochs,\n",
    "            warmup_epochs = warmup_epochs,\n",
    "            wd = weight_decay,\n",
    "            temp = temperature,\n",
    "            cmlp_ratio = class_mlp_ratio,\n",
    "            vmlp_ratio = vit_mlp_ratio\n",
    "        )\n",
    "\n",
    "data_module = ViT_DataModule(\n",
    "    train_data_dir=\"./dataset/pico-imagenet-10/train/\",\n",
    "    val_data_dir=\"./dataset/pico-imagenet-10/val/images/\",\n",
    "    test_data_dir=\"./dataset/pico-imagenet-10/test/images/\",\n",
    "    batch_size=batch\n",
    ")\n",
    "\n",
    "# Setup the Dataloaders.\n",
    "data_module.setup()\n",
    "\n",
    "# Create a PyTorch Lightning Trainer.\n",
    "trainer = pl.Trainer(\n",
    "    max_epochs=number_epochs,\n",
    "    accelerator=\"auto\",\n",
    "    devices=1 if torch.cuda.is_available() else 0,\n",
    "    log_every_n_steps=1,\n",
    "    callbacks=[my_progress_bar_call,\n",
    "               my_checkpoint_call,\n",
    "               my_lr_monitor_call,\n",
    "               my_early_stopping_call,\n",
    "               ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "halting_row=f\"Halting Hyperparameters: gamma={gamma},beta={beta},alpha_ponder={alpha_ponder},alpha_distribution={alpha_distribution},epsilon={epsilon},expected_stop_depth={expected_stop_depth}\"\n",
    "if b_laplace is not None:\n",
    "    halting_row +=f\",b_laplace={b_laplace}\"\n",
    "\n",
    "with open(\"./results/logs.csv\", 'w') as file:\n",
    "    #writing header\n",
    "    perf_header=\"Training Loss\"+\",\"+\"Training Accuracy\"+\",\"+\"Validation Loss\"+\",\"+\"Validation Top-1 Accuracy\"+\",\"+\"Validation Top-3 Accuracy\"+\",\"+\"Validation Top-5 Accuracy\"+\",\"+\"Validation Top-10 Accuracy\"\n",
    "    halt_header=''\n",
    "    for i in range(2*blocks):\n",
    "        if i<blocks:\n",
    "            string=f\"Percentage halted tokens layer_{i}\"\n",
    "        else:\n",
    "            string=f\"Variance halted tokens layer_{i-blocks}\"\n",
    "        halt_header+=\",\"+string\n",
    "    file.write(f\"Model Hypeparameters: input_size={input_size},n_patches={patches},n_blocks={blocks},n_heads={heads},hidden_d={hidden_dim},output_size={classes},batch_size={batch},learning_rate={learning_rate},weight_decay={weight_decay},temp={temperature},class_mlp_ratio={class_mlp_ratio},vit_mlp_ratio={vit_mlp_ratio}\\n\")\n",
    "    file.write(halting_row+\"\\n\")\n",
    "    file.write(perf_header+halt_header+\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6: MODEL TRAINING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "   | Name          | Type                | Params\n",
      "-------------------------------------------------------\n",
      "0  | linear_mapper | Linear              | 147 K \n",
      "1  | blocks        | ModuleList          | 4.0 M \n",
      "2  | mlp           | Sequential          | 155 K \n",
      "3  | loss          | CrossEntropyLoss    | 0     \n",
      "4  | acc_top1      | MulticlassAccuracy  | 0     \n",
      "5  | acc_top3      | MulticlassAccuracy  | 0     \n",
      "6  | acc_top5      | MulticlassAccuracy  | 0     \n",
      "7  | acc_top10     | MulticlassAccuracy  | 0     \n",
      "8  | f1score       | MulticlassF1Score   | 0     \n",
      "9  | precision     | MulticlassPrecision | 0     \n",
      "10 | recall        | MulticlassRecall    | 0     \n",
      "   | other params  | n/a                 | 192   \n",
      "-------------------------------------------------------\n",
      "4.3 M     Trainable params\n",
      "0         Non-trainable params\n",
      "4.3 M     Total params\n",
      "17.251    Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 Validation Loss -> 5.779289722442627      Validation Accuracy -> 0.1015625      Validation Accuracy Top-3 -> 0.2734375      Validation Accuracy Top-5-> 0.4296875      Validation Accuracy Top-10-> 1.0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bc315f1957c04b61a4e5d7accb6e9f8a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 Validation Loss -> 4.570472240447998      Validation Accuracy -> 0.240234375      Validation Accuracy Top-3 -> 0.5250901579856873      Validation Accuracy Top-5-> 0.7062800526618958      Validation Accuracy Top-10-> 1.0\n",
      "Epoch 0 Training Loss -> 5.793649673461914      Training Accuracy -> 0.18077531456947327\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 Validation Loss -> 4.135542869567871      Validation Accuracy -> 0.3177584111690521      Validation Accuracy Top-3 -> 0.6236478090286255      Validation Accuracy Top-5-> 0.8249699473381042      Validation Accuracy Top-10-> 1.0\n",
      "Epoch 1 Training Loss -> 4.49043083190918      Training Accuracy -> 0.2751186788082123\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2 Validation Loss -> 4.038782119750977      Validation Accuracy -> 0.3218148946762085      Validation Accuracy Top-3 -> 0.6448317170143127      Validation Accuracy Top-5-> 0.8299278616905212      Validation Accuracy Top-10-> 1.0\n",
      "Epoch 2 Training Loss -> 4.091635704040527      Training Accuracy -> 0.3301028609275818\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3 Validation Loss -> 3.7720651626586914      Validation Accuracy -> 0.40985578298568726      Validation Accuracy Top-3 -> 0.7175480723381042      Validation Accuracy Top-5-> 0.854417085647583      Validation Accuracy Top-10-> 1.0\n",
      "Epoch 3 Training Loss -> 3.8215560913085938      Training Accuracy -> 0.3791534900665283\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4 Validation Loss -> 3.6406259536743164      Validation Accuracy -> 0.39032453298568726      Validation Accuracy Top-3 -> 0.750901460647583      Validation Accuracy Top-5-> 0.8805589079856873      Validation Accuracy Top-10-> 1.0\n",
      "Epoch 4 Training Loss -> 3.5809881687164307      Training Accuracy -> 0.40446993708610535\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5 Validation Loss -> 3.380829095840454      Validation Accuracy -> 0.4917367696762085      Validation Accuracy Top-3 -> 0.806640625      Validation Accuracy Top-5-> 0.9024940133094788      Validation Accuracy Top-10-> 1.0\n",
      "Epoch 5 Training Loss -> 3.4224541187286377      Training Accuracy -> 0.4333465099334717\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6 Validation Loss -> 3.2850615978240967      Validation Accuracy -> 0.48016828298568726      Validation Accuracy Top-3 -> 0.7857571840286255      Validation Accuracy Top-5-> 0.9161658883094788      Validation Accuracy Top-10-> 1.0\n",
      "Epoch 6 Training Loss -> 3.3717026710510254      Training Accuracy -> 0.4636076092720032\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7 Validation Loss -> 2.989893674850464      Validation Accuracy -> 0.4858773946762085      Validation Accuracy Top-3 -> 0.8210636973381042      Validation Accuracy Top-5-> 0.9176682829856873      Validation Accuracy Top-10-> 1.0\n",
      "Epoch 7 Training Loss -> 3.078176736831665      Training Accuracy -> 0.49762657284736633\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8 Validation Loss -> 3.3789377212524414      Validation Accuracy -> 0.4576322138309479      Validation Accuracy Top-3 -> 0.7540565133094788      Validation Accuracy Top-5-> 0.8607271909713745      Validation Accuracy Top-10-> 1.0\n",
      "Epoch 8 Training Loss -> 3.155369758605957      Training Accuracy -> 0.4968354403972626\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9 Validation Loss -> 3.1376407146453857      Validation Accuracy -> 0.5159254670143127      Validation Accuracy Top-3 -> 0.801832914352417      Validation Accuracy Top-5-> 0.9191706776618958      Validation Accuracy Top-10-> 1.0\n",
      "Epoch 9 Training Loss -> 3.0018091201782227      Training Accuracy -> 0.5152294039726257\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10 Validation Loss -> 3.053805351257324      Validation Accuracy -> 0.4795673191547394      Validation Accuracy Top-3 -> 0.782151460647583      Validation Accuracy Top-5-> 0.9356971383094788      Validation Accuracy Top-10-> 1.0\n",
      "Epoch 10 Training Loss -> 3.0815162658691406      Training Accuracy -> 0.49723100662231445\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11 Validation Loss -> 3.1843161582946777      Validation Accuracy -> 0.4756610691547394      Validation Accuracy Top-3 -> 0.810546875      Validation Accuracy Top-5-> 0.8963341116905212      Validation Accuracy Top-10-> 1.0\n",
      "Epoch 11 Training Loss -> 3.1939947605133057      Training Accuracy -> 0.4990110695362091\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12 Validation Loss -> 2.930112361907959      Validation Accuracy -> 0.517578125      Validation Accuracy Top-3 -> 0.827073335647583      Validation Accuracy Top-5-> 0.9435096383094788      Validation Accuracy Top-10-> 1.0\n",
      "Epoch 12 Training Loss -> 2.9003708362579346      Training Accuracy -> 0.5205696225166321\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13 Validation Loss -> 2.9966793060302734      Validation Accuracy -> 0.5139723420143127      Validation Accuracy Top-3 -> 0.78515625      Validation Accuracy Top-5-> 0.9172175526618958      Validation Accuracy Top-10-> 1.0\n",
      "Epoch 13 Training Loss -> 2.8923676013946533      Training Accuracy -> 0.5278876423835754\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14 Validation Loss -> 2.9858648777008057      Validation Accuracy -> 0.4966947138309479      Validation Accuracy Top-3 -> 0.8279747366905212      Validation Accuracy Top-5-> 0.9391526579856873      Validation Accuracy Top-10-> 1.0\n",
      "Epoch 14 Training Loss -> 2.8575711250305176      Training Accuracy -> 0.5361946225166321\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15 Validation Loss -> 2.9438576698303223      Validation Accuracy -> 0.520432710647583      Validation Accuracy Top-3 -> 0.8299278616905212      Validation Accuracy Top-5-> 0.9332932829856873      Validation Accuracy Top-10-> 1.0\n",
      "Epoch 15 Training Loss -> 2.863935708999634      Training Accuracy -> 0.561313271522522\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16 Validation Loss -> 2.6312131881713867      Validation Accuracy -> 0.532151460647583      Validation Accuracy Top-3 -> 0.8221153616905212      Validation Accuracy Top-5-> 0.9513221383094788      Validation Accuracy Top-10-> 1.0\n",
      "Epoch 16 Training Loss -> 2.773505449295044      Training Accuracy -> 0.5625\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17 Validation Loss -> 3.2071075439453125      Validation Accuracy -> 0.48362380266189575      Validation Accuracy Top-3 -> 0.7995793223381042      Validation Accuracy Top-5-> 0.9185696840286255      Validation Accuracy Top-10-> 1.0\n",
      "Epoch 17 Training Loss -> 2.6339497566223145      Training Accuracy -> 0.5717958807945251\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18 Validation Loss -> 2.8313393592834473      Validation Accuracy -> 0.5703125      Validation Accuracy Top-3 -> 0.8227163553237915      Validation Accuracy Top-5-> 0.9269831776618958      Validation Accuracy Top-10-> 1.0\n",
      "Epoch 18 Training Loss -> 2.5974583625793457      Training Accuracy -> 0.5856408476829529\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19 Validation Loss -> 2.6156346797943115      Validation Accuracy -> 0.5803785920143127      Validation Accuracy Top-3 -> 0.8308293223381042      Validation Accuracy Top-5-> 0.954176664352417      Validation Accuracy Top-10-> 1.0\n",
      "Epoch 19 Training Loss -> 2.4266560077667236      Training Accuracy -> 0.608781635761261\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20 Validation Loss -> 3.6527204513549805      Validation Accuracy -> 0.46213942766189575      Validation Accuracy Top-3 -> 0.767578125      Validation Accuracy Top-5-> 0.8952824473381042      Validation Accuracy Top-10-> 1.0\n",
      "Epoch 20 Training Loss -> 2.6643471717834473      Training Accuracy -> 0.576344907283783\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21 Validation Loss -> 2.825448989868164      Validation Accuracy -> 0.53515625      Validation Accuracy Top-3 -> 0.829026460647583      Validation Accuracy Top-5-> 0.9226261973381042      Validation Accuracy Top-10-> 1.0\n",
      "Epoch 21 Training Loss -> 2.670865297317505      Training Accuracy -> 0.5623022317886353\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22 Validation Loss -> 3.21404767036438      Validation Accuracy -> 0.46995192766189575      Validation Accuracy Top-3 -> 0.8001803159713745      Validation Accuracy Top-5-> 0.9000901579856873      Validation Accuracy Top-10-> 1.0\n",
      "Epoch 22 Training Loss -> 2.575019121170044      Training Accuracy -> 0.5846518874168396\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5f5ca9c0fabb446cbe8f9d4546c87fd0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23 Validation Loss -> 2.7259950637817383      Validation Accuracy -> 0.5551382303237915      Validation Accuracy Top-3 -> 0.8294771909713745      Validation Accuracy Top-5-> 0.9323918223381042      Validation Accuracy Top-10-> 1.0\n",
      "Epoch 23 Training Loss -> 2.5956315994262695      Training Accuracy -> 0.5791139006614685\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "03d26d189d31443daad98b8909b223be",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24 Validation Loss -> 2.842040777206421      Validation Accuracy -> 0.5345553159713745      Validation Accuracy Top-3 -> 0.8425480723381042      Validation Accuracy Top-5-> 0.9308894276618958      Validation Accuracy Top-10-> 1.0\n",
      "Epoch 24 Training Loss -> 2.522404670715332      Training Accuracy -> 0.5927610993385315\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f4ce78d2e18e4196902f5f35a639c398",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25 Validation Loss -> 2.765543222427368      Validation Accuracy -> 0.5901442170143127      Validation Accuracy Top-3 -> 0.8523136973381042      Validation Accuracy Top-5-> 0.9526742696762085      Validation Accuracy Top-10-> 1.0\n",
      "Epoch 25 Training Loss -> 2.4891159534454346      Training Accuracy -> 0.6004746556282043\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "92ff3d42f872411c8860ab7ea21aeb78",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26 Validation Loss -> 2.7684812545776367      Validation Accuracy -> 0.5482271909713745      Validation Accuracy Top-3 -> 0.8353365659713745      Validation Accuracy Top-5-> 0.9347956776618958      Validation Accuracy Top-10-> 1.0\n",
      "Epoch 26 Training Loss -> 2.307269811630249      Training Accuracy -> 0.6184731125831604\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e5ddd60f56c04949a56c5ec604e8baf3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27 Validation Loss -> 2.694619655609131      Validation Accuracy -> 0.5920973420143127      Validation Accuracy Top-3 -> 0.8440504670143127      Validation Accuracy Top-5-> 0.938551664352417      Validation Accuracy Top-10-> 1.0\n",
      "Epoch 27 Training Loss -> 2.245108127593994      Training Accuracy -> 0.6358781456947327\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "531f65eb396a4d01a6abf0fc7178fec3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28 Validation Loss -> 2.9260776042938232      Validation Accuracy -> 0.5609976053237915      Validation Accuracy Top-3 -> 0.8386418223381042      Validation Accuracy Top-5-> 0.9322415590286255      Validation Accuracy Top-10-> 1.0\n",
      "Epoch 28 Training Loss -> 2.332860231399536      Training Accuracy -> 0.6323180198669434\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b8405868973b432bb563821c6dd1b6c3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29 Validation Loss -> 2.8627216815948486      Validation Accuracy -> 0.560546875      Validation Accuracy Top-3 -> 0.8533653616905212      Validation Accuracy Top-5-> 0.9356971383094788      Validation Accuracy Top-10-> 1.0\n",
      "Epoch 29 Training Loss -> 2.1704866886138916      Training Accuracy -> 0.6518987417221069\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "494e6ff0054144c78de95d51bcc6dbde",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30 Validation Loss -> 2.9779179096221924      Validation Accuracy -> 0.5297476053237915      Validation Accuracy Top-3 -> 0.8128004670143127      Validation Accuracy Top-5-> 0.9400540590286255      Validation Accuracy Top-10-> 1.0\n",
      "Epoch 30 Training Loss -> 2.4923243522644043      Training Accuracy -> 0.611155092716217\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "13f0efa5baaa4061b5ef811abc63e7b0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 31 Validation Loss -> 2.952495813369751      Validation Accuracy -> 0.561448335647583      Validation Accuracy Top-3 -> 0.8103966116905212      Validation Accuracy Top-5-> 0.9196214079856873      Validation Accuracy Top-10-> 1.0\n",
      "Epoch 31 Training Loss -> 2.4106593132019043      Training Accuracy -> 0.609968364238739\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ed35a6dc9d5b49278e938ef3ae266098",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 32 Validation Loss -> 2.9326834678649902      Validation Accuracy -> 0.5268930196762085      Validation Accuracy Top-3 -> 0.8559194803237915      Validation Accuracy Top-5-> 0.9376502633094788      Validation Accuracy Top-10-> 1.0\n",
      "Epoch 32 Training Loss -> 2.4189324378967285      Training Accuracy -> 0.6147152185440063\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7e2353c1d4b04a8ea24c2d3e5f232fe3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 33 Validation Loss -> 3.1686148643493652      Validation Accuracy -> 0.530198335647583      Validation Accuracy Top-3 -> 0.825120210647583      Validation Accuracy Top-5-> 0.9317908883094788      Validation Accuracy Top-10-> 1.0\n",
      "Epoch 33 Training Loss -> 2.302180290222168      Training Accuracy -> 0.6380537748336792\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "27c77316e5374b0492e8baaeea390ff5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 34 Validation Loss -> 2.6391847133636475      Validation Accuracy -> 0.5815805196762085      Validation Accuracy Top-3 -> 0.8431490659713745      Validation Accuracy Top-5-> 0.9439603090286255      Validation Accuracy Top-10-> 1.0\n",
      "Epoch 34 Training Loss -> 2.2755849361419678      Training Accuracy -> 0.6429983973503113\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7845da3455e84807945720cfe79bd653",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 35 Validation Loss -> 3.0245718955993652      Validation Accuracy -> 0.5494290590286255      Validation Accuracy Top-3 -> 0.832932710647583      Validation Accuracy Top-5-> 0.9313401579856873      Validation Accuracy Top-10-> 1.0\n",
      "Epoch 35 Training Loss -> 2.130359649658203      Training Accuracy -> 0.6653481125831604\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eb8ce5b510e545469f9df6bbdff25a18",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 36 Validation Loss -> 2.8410744667053223      Validation Accuracy -> 0.5844351053237915      Validation Accuracy Top-3 -> 0.8670372366905212      Validation Accuracy Top-5-> 0.952223539352417      Validation Accuracy Top-10-> 1.0\n",
      "Epoch 36 Training Loss -> 1.9651846885681152      Training Accuracy -> 0.6696993708610535\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5e9cc9d3d97d4e7db040ecbd24da2422",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 37 Validation Loss -> 2.870518922805786      Validation Accuracy -> 0.5844351053237915      Validation Accuracy Top-3 -> 0.8592247366905212      Validation Accuracy Top-5-> 0.9409555196762085      Validation Accuracy Top-10-> 1.0\n",
      "Epoch 37 Training Loss -> 2.0212924480438232      Training Accuracy -> 0.671875\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c616e9b1664b4b2e805560af0b4e0533",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 38 Validation Loss -> 2.903003454208374      Validation Accuracy -> 0.5875901579856873      Validation Accuracy Top-3 -> 0.8401442170143127      Validation Accuracy Top-5-> 0.9376502633094788      Validation Accuracy Top-10-> 1.0\n",
      "Epoch 38 Training Loss -> 1.9744060039520264      Training Accuracy -> 0.686313271522522\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "692536c1db8046ceb82f843f8fa497e2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 39 Validation Loss -> 3.3633618354797363      Validation Accuracy -> 0.5366586446762085      Validation Accuracy Top-3 -> 0.8396934866905212      Validation Accuracy Top-5-> 0.9341946840286255      Validation Accuracy Top-10-> 1.0\n",
      "Epoch 39 Training Loss -> 1.8619508743286133      Training Accuracy -> 0.6930379867553711\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "387055ee95c5452595505f81047e64cf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 40 Validation Loss -> 3.339387893676758      Validation Accuracy -> 0.5411658883094788      Validation Accuracy Top-3 -> 0.8197115659713745      Validation Accuracy Top-5-> 0.9215745329856873      Validation Accuracy Top-10-> 1.0\n",
      "Epoch 40 Training Loss -> 1.9897619485855103      Training Accuracy -> 0.6829509735107422\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eccf28c52a98414c8c71b3aca34e0c33",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 41 Validation Loss -> 3.111830472946167      Validation Accuracy -> 0.590745210647583      Validation Accuracy Top-3 -> 0.8353365659713745      Validation Accuracy Top-5-> 0.922926664352417      Validation Accuracy Top-10-> 1.0\n",
      "Epoch 41 Training Loss -> 2.0604705810546875      Training Accuracy -> 0.6641613841056824\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a6e3e2c10e6e47e587e221913a05d3a0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 42 Validation Loss -> 2.532170295715332      Validation Accuracy -> 0.5902944803237915      Validation Accuracy Top-3 -> 0.841796875      Validation Accuracy Top-5-> 0.9328425526618958      Validation Accuracy Top-10-> 1.0\n",
      "Epoch 42 Training Loss -> 2.229607343673706      Training Accuracy -> 0.6329113841056824\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ba86bd6a53644046b3661b102c072e2d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 43 Validation Loss -> 2.9163291454315186      Validation Accuracy -> 0.588942289352417      Validation Accuracy Top-3 -> 0.8757511973381042      Validation Accuracy Top-5-> 0.9513221383094788      Validation Accuracy Top-10-> 1.0\n",
      "Epoch 43 Training Loss -> 2.1531965732574463      Training Accuracy -> 0.6542721390724182\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ade0f571e8364065b8d99297705d12f0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 44 Validation Loss -> 3.4752578735351562      Validation Accuracy -> 0.4966947138309479      Validation Accuracy Top-3 -> 0.8411959409713745      Validation Accuracy Top-5-> 0.9420071840286255      Validation Accuracy Top-10-> 1.0\n",
      "Epoch 44 Training Loss -> 1.9737461805343628      Training Accuracy -> 0.6789952516555786\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "18502d9bfa32444399c2e2b357614d02",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 45 Validation Loss -> 2.5882744789123535      Validation Accuracy -> 0.5844351053237915      Validation Accuracy Top-3 -> 0.8679386973381042      Validation Accuracy Top-5-> 0.956129789352417      Validation Accuracy Top-10-> 1.0\n",
      "Epoch 45 Training Loss -> 1.8581262826919556      Training Accuracy -> 0.6898733973503113\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b145ce8b0b824fad99199ba2c7cc69cb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 46 Validation Loss -> 3.014923572540283      Validation Accuracy -> 0.5785757303237915      Validation Accuracy Top-3 -> 0.8572716116905212      Validation Accuracy Top-5-> 0.9454627633094788      Validation Accuracy Top-10-> 1.0\n",
      "Epoch 46 Training Loss -> 1.8117084503173828      Training Accuracy -> 0.7126186490058899\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e2c0261e4c2d4f93bdc6fae1520ecbc4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 47 Validation Loss -> 2.8802669048309326      Validation Accuracy -> 0.5434194803237915      Validation Accuracy Top-3 -> 0.8099459409713745      Validation Accuracy Top-5-> 0.9054988026618958      Validation Accuracy Top-10-> 1.0\n",
      "Epoch 47 Training Loss -> 1.6360191106796265      Training Accuracy -> 0.7464398741722107\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "01074730600746718f87279a21b95dc0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 48 Validation Loss -> 2.9988253116607666      Validation Accuracy -> 0.584885835647583      Validation Accuracy Top-3 -> 0.8377403616905212      Validation Accuracy Top-5-> 0.9487680196762085      Validation Accuracy Top-10-> 1.0\n",
      "Epoch 48 Training Loss -> 1.6398800611495972      Training Accuracy -> 0.7434731125831604\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "trainer.fit(model.to(\"cuda\"), data_module)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path=\"./results/\"\n",
    "# Plotting Performace metrics\n",
    "def plotter(data, xlabel, ylabel, title, is_halting):\n",
    "    if is_halting:\n",
    "        plt.style.use('bmh')\n",
    "    plt.xticks([i for i in range(len(data))])\n",
    "    plt.plot(data,marker=\"o\")\n",
    "    plt.title(title)\n",
    "    plt.xlabel(xlabel)\n",
    "    plt.ylabel(ylabel)\n",
    "    name=title.replace(\" \",\"_\")\n",
    "    plt.savefig(save_path+f\"{name}.png\")\n",
    "    plt.show()\n",
    "\n",
    "# Removing first element.\n",
    "val_loss=[x for x in model.val_loss[1:]]\n",
    "val_acc1=[x for x in model.val_acc1[1:]]\n",
    "val_acc3=[x for x in model.val_acc3[1:]]\n",
    "val_acc5=[x for x in model.val_acc5[1:]]\n",
    "val_acc10=[x for x in model.val_acc10[1:]]\n",
    "\n",
    "# print(\"Performance lists: \")\n",
    "# print(model.train_loss)\n",
    "# print(model.train_acc)\n",
    "# print(val_loss)\n",
    "# print(val_acc1)\n",
    "# print(val_acc3)\n",
    "# print(val_acc5)\n",
    "# print(val_acc10)\n",
    "# print(model.perc)\n",
    "# print(model.var)\n",
    "\n",
    "# Plotting.\n",
    "plotter(model.train_loss,\"epochs\",\"loss\",\"Train Loss\",False)\n",
    "plotter(model.train_acc,\"epochs\",\"accuracy\",\"Train Accuracy\",False)\n",
    "plotter(val_loss,\"epochs\",\"loss\",\"Validation Loss\",False)\n",
    "plotter(val_acc1,\"epochs\",\"accuracy\",\"Validation Top-1 Accuracy\",False)\n",
    "plotter(val_acc3,\"epochs\",\"accuracy\",\"Validation Top-3 Accuracy\",False)\n",
    "plotter(val_acc5,\"epochs\",\"accuracy\",\"Validation Top-5 Accuracy\",False)\n",
    "plotter(val_acc10,\"epochs\",\"accuracy\",\"Validation Top-10 Accuracy\",False)\n",
    "plotter(model.perc[-1],\"layers\",\"percentage\",\"Percentage Halted Tokens\",True)\n",
    "plotter(model.var[-1],\"layers\",\"variance\",\"Variance Halted Tokens\",True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7: MODEL SAVING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the path of the best Model.\n",
    "best_model_path = my_checkpoint_call.best_model_path\n",
    "\n",
    "# Load the best model from the Checkpoint.\n",
    "best_model = ViT.load_from_checkpoint(\n",
    "                   checkpoint_path=best_model_path,\n",
    "                   input_d = input_size,\n",
    "                   batch_size=batch,\n",
    "                   n_patches = patches,\n",
    "                   n_blocks = blocks,\n",
    "                   hidden_d = hidden_dim,\n",
    "                   n_heads = heads,\n",
    "                   out_d = classes,\n",
    "                   lr = learning_rate,\n",
    "                   nepochs = number_epochs,\n",
    "                   warmup_epochs = warmup_epochs,\n",
    "                   wd = weight_decay,\n",
    "                   temp = temperature,\n",
    "                   cmlp_ratio = class_mlp_ratio,\n",
    "                   vmlp_ratio = vit_mlp_ratio,\n",
    "                   )\n",
    "\n",
    "# Access the Best Model's Accuracy.\n",
    "best_model_accuracy = trainer.checkpoint_callback.best_model_score.item()\n",
    "print(f\"Best Model Accuracy: {best_model_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Save it as a pth file.\n",
    "# Specify the path where you want to save the model.\n",
    "model_path = f\"./models/best_model_acc_{best_model_accuracy:.5f}.pth\"\n",
    "\n",
    "# Save the model's state dict to the specified file.\n",
    "torch.save(best_model.state_dict(), model_path)\n",
    "\n",
    "# Save it as a CheckPoint (Specific of PyTorch Lightning = Model State Dictionary + Training State + Optimizer State).\n",
    "# Specify the path where you want to save the model checkpoint.\n",
    "ckpt_path = f\"./models/best_model_acc_{best_model_accuracy:.5f}.ckpt\"\n",
    "\n",
    "# Save the model's state dict to the specified file.\n",
    "torch.save(best_model.state_dict(), ckpt_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "default:Python",
   "language": "python",
   "name": "conda-env-default-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
