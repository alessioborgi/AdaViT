{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# (AdaViT) ADAPTIVE VISION TRANSFORMERS\n",
    "\n",
    "### SAPIENZA UNIVESITY of ROME (DEPARTMENT OF COMPUTER, CONTROL AND MANAGEMENT ENGINEEERING)\n",
    "\n",
    "### COURSE IN ARTIFICIAL INTELLIGENCE AND ROBOTICS (ACADEMIC YEAR 2023/2024)\n",
    "\n",
    "### AUTHOR:  **ALESSIO BORGI**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!kaggle datasets download -d alessioborgi/pico-imagenet-10\n",
    "#!unzip -q pico-imagenet-10.zip\n",
    "#!mv \"pico-imagenet\" dataset\n",
    "\n",
    "\n",
    "#!kaggle datasets download -d alessioborgi/nano-imagenet-30\n",
    "#!unzip -q nano-imagenet-30.zip\n",
    "#!mv \"nano-imagenet\" dataset\n",
    "\n",
    "\n",
    "#!kaggle datasets download -d alessioborgi/tiny-imagenet-200\n",
    "# !unzip -q tiny-imagenet-200.zip\n",
    "# !mv \"tiny-imagenet-200\" dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0: IMPORTING LIBRARIES \\& SETTINGS\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Importing PyTorch-related Libraries.\n",
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torchvision import datasets\n",
    "from torchvision import transforms\n",
    "from torch.nn import CrossEntropyLoss\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torchvision.transforms import ToPILImage\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR,CosineAnnealingWarmRestarts\n",
    "from torchmetrics.classification import Accuracy, MulticlassF1Score, MulticlassPrecision, MulticlassRecall\n",
    "\n",
    "# Importing PyTorch Lightning-Related Libraries.\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.callbacks.progress import TQDMProgressBar\n",
    "from pytorch_lightning.loggers import TensorBoardLogger, CSVLogger\n",
    "from pytorch_lightning.callbacks import TQDMProgressBar, LearningRateMonitor, ModelCheckpoint\n",
    "\n",
    "# Importing General Libraries.\n",
    "import os\n",
    "import csv\n",
    "import PIL\n",
    "import time\n",
    "import math\n",
    "import glob\n",
    "import random\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "from scipy.stats import norm\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import OrderedDict\n",
    "\n",
    "# Importing from Other Files.\n",
    "from .Train_Val_Test_Classes import CustomTrainingTinyImagenet, CustomValidationTinyImagenet, CustomTestTinyImagenet\n",
    "from .Tranformations import AdaViT_Transformations\n",
    "from .Multi_Head_Self_Attention import \n",
    "from .Positional_Embeddings import get_positional_embeddings_RoPE, get_positional_embeddings_SPE, get_positional_embeddings_BERT\n",
    "from .Gumbel_Noise import add_gumbel_noise\n",
    "from .utils import set_device, seed_everything\n",
    "from .Patchifying import make_matches_from_image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1: DATAMODULE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class AViT_DataModule(pl.LightningDataModule):\n",
    "\n",
    "    def __init__(self, train_data_dir, val_data_dir, test_data_dir, batch_size, num_workers=4):\n",
    "        \"\"\"\n",
    "        Custom data module for AViT model training and validation.\n",
    "\n",
    "        Args:\n",
    "        - train_data_dir (str): Directory path for the training dataset.\n",
    "        - val_data_dir (str): Directory path for the validation dataset.\n",
    "        - batch_size (int): Batch size for training and validation DataLoader.\n",
    "        - num_workers (int, optional): Number of workers for DataLoader (default is 4).\n",
    "        \"\"\"\n",
    "        super(AViT_DataModule, self).__init__()\n",
    "        self.train_data_dir = train_data_dir\n",
    "        self.val_data_dir = val_data_dir\n",
    "        self.test_data_dir = test_data_dir\n",
    "        self.batch_size = batch_size\n",
    "        self.batch_size_test = 5\n",
    "        self.num_workers = num_workers\n",
    "\n",
    "        # Use AdaViT transformations for data augmentation\n",
    "        self.transform = AdaViT_Transformations()\n",
    "\n",
    "    def setup(self, stage=None):\n",
    "        \"\"\"\n",
    "        Method to load and configure datasets for Training and Validation.\n",
    "\n",
    "        Args:\n",
    "        - stage (str, optional): 'fit' for Training and 'test' for Validation (default is None).\n",
    "        \"\"\"\n",
    "        # Load Train dataset using CustomTrainingTinyImagenet with the new directory structure.\n",
    "        self.train_dataset = CustomTrainingTinyImagenet(self.train_data_dir, transform=self.transform)\n",
    "\n",
    "        # Load Validation dataset.\n",
    "        self.val_dataset = CustomValidationTinyImagenet(self.val_data_dir, transform=self.transform)\n",
    "\n",
    "        # Load Test dataset.\n",
    "        self.test_dataset = CustomTestTinyImagenet(self.test_data_dir, transform=self.transform)\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        \"\"\"\n",
    "        Method to return the DataLoader for the Training Dataset.\n",
    "\n",
    "        Returns:\n",
    "        - train_dataloader (DataLoader): DataLoader for Training.\n",
    "        \"\"\"\n",
    "        return DataLoader(self.train_dataset, batch_size=self.batch_size, num_workers=self.num_workers, shuffle=True)\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        \"\"\"\n",
    "        Method to return the DataLoader for the Validation Dataset.\n",
    "\n",
    "        Returns:\n",
    "        - val_dataloader (DataLoader): DataLoader for Validation.\n",
    "        \"\"\"\n",
    "        return DataLoader(self.val_dataset, batch_size=self.batch_size, num_workers=self.num_workers)\n",
    "\n",
    "    def test_dataloader(self):\n",
    "        \"\"\"\n",
    "        Method to return the DataLoader for the Test Dataset.\n",
    "\n",
    "        Returns:\n",
    "        - test_dataloader (DataLoader): DataLoader for Test Set.\n",
    "        \"\"\"\n",
    "        return DataLoader(self.test_dataset, batch_size=self.batch_size_test, num_workers=self.num_workers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2: VIT-BLOCK "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ViT_Block_Layer_Norm(nn.Module):\n",
    "    def __init__(self, hidden_d, n_heads, mlp_ratio=10):\n",
    "        super(ViT_Block_Layer_Norm, self).__init__()\n",
    "        \n",
    "        self.hidden_d = hidden_d\n",
    "        self.n_heads = n_heads\n",
    "\n",
    "        self.norm1 = nn.LayerNorm(hidden_d)\n",
    "        self.mhsa = MyMHSA(hidden_d, n_heads)\n",
    "        self.norm2 = nn.LayerNorm(hidden_d)\n",
    "        self.mlp = nn.Sequential(\n",
    "            nn.Linear(hidden_d, mlp_ratio * hidden_d),\n",
    "            nn.GELU(),\n",
    "            nn.Linear(mlp_ratio * hidden_d, hidden_d),\n",
    "        )\n",
    "        \n",
    "        # Initialize weights.\n",
    "        self.initialize_weights_block()\n",
    "\n",
    "    def forward(self, x):\n",
    "        \n",
    "        out = x + self.mhsa(self.norm1(x))\n",
    "        out = out + self.mlp(self.norm2(out))\n",
    "        return out\n",
    "    \n",
    "    def initialize_weights_block(self):\n",
    "        \n",
    "        # Initialize weights for linear layers in mlp.\n",
    "        for layer in self.mlp:\n",
    "            if isinstance(layer, nn.Linear):\n",
    "                nn.init.xavier_uniform_(layer.weight)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3: VIT DEFINITION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class Vision_Transformer(nn.Module):\n",
    "\n",
    "    def __init__(self, chw, batch_size, n_patches, n_blocks, hidden_d, n_heads, out_d, lr, nepochs, warmup_epochs, wd, temp, cmlp_ratio, vmlp_ratio):\n",
    "        \"\"\"\n",
    "        Initialize the Vision_Transformer model.\n",
    "\n",
    "        Parameters:\n",
    "        - input_d (int): Dimension of the input.\n",
    "        - n_patches (int): Number of patches.\n",
    "        - n_blocks (int): Number of transformer blocks.\n",
    "        - hidden_d (int): Dimension of the hidden layer.\n",
    "        - n_heads (int): Number of attention heads.\n",
    "        - out_d (int): Output dimension.\n",
    "        - lr (float): Learning rate.\n",
    "        - wd (float): Weight decay.\n",
    "        - temp (float): Temperature scaling.\n",
    "        - cmlp_ratio (int): Ratio for the classification MLP.\n",
    "        - vmlp_ratio (int): Ratio for the ViT MLP.\n",
    "        \"\"\"\n",
    "\n",
    "        # Super Constructor.\n",
    "        super(Vision_Transformer, self).__init__()\n",
    "\n",
    "        # Model Attributes.\n",
    "        self.chw = chw # ( C , H , W )\n",
    "        self.n_patches = n_patches\n",
    "        self.n_blocks = n_blocks\n",
    "        self.n_heads = n_heads\n",
    "        self.hidden_d = hidden_d\n",
    "        self.class_mlp_ratio = cmlp_ratio\n",
    "        self.vit_mlp_ratio = vmlp_ratio\n",
    "\n",
    "    \n",
    "        # Input and Patches Sizes.\n",
    "        assert chw[1] % n_patches == 0, \"Input shape not entirely divisible by number of patches\"\n",
    "        assert chw[2] % n_patches == 0, \"Input shape not entirely divisible by number of patches\"\n",
    "        self.patch_size = (chw[1] / n_patches, chw[2] / n_patches)\n",
    "\n",
    "        # 1) Linear Mapper.\n",
    "        self.input_d = int(chw[0] * self.patch_size[0] * self.patch_size[1])\n",
    "        self.linear_mapper = nn.Linear(self.input_d, self.hidden_d)\n",
    "\n",
    "        # 2) Learnable Classification Token.\n",
    "        self.class_token = nn.Parameter(torch.rand(1, self.hidden_d))\n",
    "\n",
    "        # 3) Positional Embedding.\n",
    "        #self.register_buffer('positional_embeddings', get_positional_embeddings_SPE(n_patches ** 2 + 1, self.hidden_d), persistent=False)\n",
    "        self.register_buffer('positional_embeddings', get_positional_embeddings_RoPE(n_patches ** 2 + 1, self.hidden_d), persistent=False)\n",
    "\n",
    "        # 4) Transformer Encoder Blocks.\n",
    "        # Select one of the following blocks.\n",
    "        # 4.1) Transformer Block with Layer Normalization.\n",
    "        self.blocks = nn.ModuleList([ViT_Block_Layer_Norm(self.hidden_d, self.n_heads,self.vit_mlp_ratio) for _ in range(self.n_blocks)])\n",
    "\n",
    "        # 5) Classification MLP.\n",
    "        self.mlp = nn.Sequential(\n",
    "          nn.Linear(self.hidden_d, class_mlp_ratio * hidden_d),\n",
    "          nn.GELU(),\n",
    "          nn.Linear(class_mlp_ratio * hidden_d, out_d),\n",
    "        )\n",
    "\n",
    "        # Initialize weights.\n",
    "        self.initialize_weights()\n",
    "\n",
    "    def forward(self, images):\n",
    "        \"\"\"\n",
    "        Forward pass of the Vision_Transformer model.\n",
    "\n",
    "        Parameters:\n",
    "        - images (torch.Tensor): Input images tensor.\n",
    "\n",
    "        Returns:\n",
    "        torch.Tensor: Output tensor.\n",
    "        \"\"\"\n",
    "\n",
    "        # Dividing Images into Patches.\n",
    "        n, c, h, w = images.shape\n",
    "        patches = make_matches_from_image(images, self.n_patches).to(self.positional_embeddings.device)\n",
    "\n",
    "        # Running Linear Layer Tokenization.\n",
    "        # Map the Vector corresponding to each patch to the Hidden Size Dimension.\n",
    "        tokens = self.linear_mapper(patches)\n",
    "\n",
    "        # Adding Classification Token to the Tokens.\n",
    "        tokens = torch.cat((self.class_token.expand(n, 1, -1), tokens), dim=1).to(\"cuda\")\n",
    "\n",
    "        # Adding Positional Embedding.\n",
    "        out = tokens + self.positional_embeddings.repeat(n, 1, 1).to(\"cuda\")\n",
    "\n",
    "        # Transformer Blocks.\n",
    "        for block in self.blocks:\n",
    "            \n",
    "            out = block(out)\n",
    "            \n",
    "        out = out[:, 0]\n",
    "        \n",
    "        return self.mlp(out)\n",
    "\n",
    "\n",
    "    def initialize_weights(self):\n",
    "        \"\"\"\n",
    "        Initialize weights for linear layers, embeddings, etc.\n",
    "        \"\"\"\n",
    "\n",
    "        # Initialize Weights for Linear Layers, Embeddings, etc.\n",
    "        nn.init.xavier_uniform_(self.linear_mapper.weight)\n",
    "        nn.init.normal_(self.class_token.data)\n",
    "\n",
    "        # Initialize Weights for Classification MLP.\n",
    "        nn.init.xavier_uniform_(self.mlp[0].weight)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class ViT(Vision_Transformer, pl.LightningModule):\n",
    "\n",
    "    def __init__(self, input_d, batch_size, n_patches, n_blocks, hidden_d, n_heads, out_d, lr, nepochs, warmup_epochs, wd, temp, cmlp_ratio, vmlp_ratio):\n",
    "        \"\"\"\n",
    "        Initialize the ViT, a LightningModule using Vision_Transformer as a base.\n",
    "\n",
    "        Parameters:\n",
    "        - input_d (int): Dimension of the input.\n",
    "        - n_patches (int): Number of patches.\n",
    "        - n_blocks (int): Number of transformer blocks.\n",
    "        - hidden_d (int): Dimension of the hidden layer.\n",
    "        - n_heads (int): Number of attention heads.\n",
    "        - out_d (int): Output dimension.\n",
    "        - lr (float): Learning rate.\n",
    "        - wd (float): Weight decay.\n",
    "        - temp (float): Temperature scaling.\n",
    "        - cmlp_ratio (int): Ratio for the classification MLP.\n",
    "        - vmlp_ratio (int): Ratio for the ViT MLP.\n",
    "        \"\"\"\n",
    "        super(ViT, self).__init__(input_d, batch_size, n_patches, n_blocks, hidden_d, n_heads, out_d, lr, nepochs, warmup_epochs, wd, temp, cmlp_ratio, vmlp_ratio)\n",
    "        # Optimizer hyperparams.\n",
    "        self.learning_rate = lr\n",
    "        self.nepochs = nepochs\n",
    "        self.weight_decay = wd\n",
    "        self.warmup_epochs = warmup_epochs\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "        # Definition of the Cross Entropy Loss.\n",
    "        self.loss = CrossEntropyLoss()\n",
    "        self.temperature = temp\n",
    "\n",
    "        # Definition of Accuracies, F1Score, Precision, and Recall Metrics.\n",
    "        self.acc_top1 = Accuracy(task=\"multiclass\", num_classes=out_d)\n",
    "        self.acc_top3 = Accuracy(task=\"multiclass\", num_classes=out_d, top_k=3)\n",
    "        self.acc_top5 = Accuracy(task=\"multiclass\", num_classes=out_d, top_k=5)\n",
    "        self.acc_top10 = Accuracy(task=\"multiclass\", num_classes=out_d, top_k=10)\n",
    "        self.f1score = MulticlassF1Score(num_classes=out_d, average='macro')\n",
    "        self.precision = MulticlassPrecision(num_classes=out_d, average='macro')\n",
    "        self.recall = MulticlassRecall(num_classes=out_d, average='macro')\n",
    "\n",
    "        # Definition of lists to be used in the \"on_ ... _epoch_end\" functions.\n",
    "        self.training_step_outputs = []\n",
    "        self.validation_step_outputs = []\n",
    "        self.test_step_outputs = []\n",
    "\n",
    "        #list of train and validation per epochs performance\n",
    "        self.train_loss=[]\n",
    "        self.train_acc=[]\n",
    "        self.val_loss=[]\n",
    "        self.val_acc1=[]\n",
    "        self.val_acc3=[]\n",
    "        self.val_acc5=[]\n",
    "        self.val_acc10=[]\n",
    "        self.perc=[]\n",
    "        self.var=[]\n",
    "\n",
    "    def _step(self, batch):\n",
    "        \"\"\"\n",
    "        Common computation of the metrics among Training, Validation, and Test Set.\n",
    "\n",
    "        Parameters:\n",
    "        - batch (tuple): Input batch tuple.\n",
    "\n",
    "        Returns:\n",
    "        tuple: Tuple containing loss and various metrics.\n",
    "        \"\"\"\n",
    "        x, y = batch\n",
    "        # Compute the Logits.\n",
    "        preds = self(x)\n",
    "        # Scale the logits using a Temperature Scaling and add Gumbel Noise, s.t. you obtain Gumbel Softmax then.\n",
    "        preds_scaled = add_gumbel_noise(preds) / self.temperature\n",
    "        loss = self.loss(preds_scaled, y) \n",
    "        acc1 = self.acc_top1(preds, y)\n",
    "        acc3 = self.acc_top3(preds, y)\n",
    "        acc5 = self.acc_top5(preds, y)\n",
    "        acc10 = self.acc_top10(preds, y)\n",
    "        f1score = self.f1score(preds, y)\n",
    "        precision = self.precision(preds, y)\n",
    "        recall = self.recall(preds, y)\n",
    "\n",
    "        return loss, acc1, acc3, acc5, acc10, f1score, precision, recall\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        \"\"\"\n",
    "        Training step function.\n",
    "\n",
    "        Parameters:\n",
    "        - batch (tuple): Input batch tuple.\n",
    "        - batch_idx (int): Batch index.\n",
    "\n",
    "        Returns:\n",
    "        torch.Tensor: Training loss.\n",
    "        \"\"\"\n",
    "        # Compute the Training Loss and Accuracy.\n",
    "        loss, acc, _, _, _, _, _, _ = self._step(batch)\n",
    "\n",
    "        # Create a Dictionary to represent the output of the Training step.\n",
    "        training_step_output = {\n",
    "            \"train_loss\": loss.item(),\n",
    "            \"train_acc\": acc.item()\n",
    "        }\n",
    "\n",
    "        # Append the dictionary to the list.\n",
    "        self.training_step_outputs.append(training_step_output)\n",
    "\n",
    "        # Perform logging.\n",
    "        self.log(\"train_loss\", loss, on_step=True, on_epoch=True, prog_bar=True, logger=True)\n",
    "        self.log(\"train_acc\", acc, on_step=True, on_epoch=True, prog_bar=True, logger=True)\n",
    "\n",
    "        return loss\n",
    "\n",
    "    def on_train_epoch_end(self):\n",
    "        \"\"\"\n",
    "        Method called at the end of the training epoch.\n",
    "        Returns:\n",
    "        None\n",
    "        \"\"\"\n",
    "        # Calculate the Mean Loss and Accuracy from the list of dictionaries.\n",
    "        loss_tot = torch.tensor([item[\"train_loss\"] for item in self.training_step_outputs]).mean().to(\"cuda\")\n",
    "        acc_tot = torch.tensor([item[\"train_acc\"] for item in self.training_step_outputs]).mean().to(\"cuda\")\n",
    "\n",
    "        # Log the mean values.\n",
    "        self.log(\"train_loss\", loss_tot)\n",
    "        self.log(\"train_acc\", acc_tot)\n",
    "\n",
    "        # Print messages.\n",
    "        message_loss = f'Epoch {self.current_epoch} Training Loss -> {loss_tot}'\n",
    "        message_accuracy = f'      Training Accuracy -> {acc_tot}'\n",
    "        print(message_loss + message_accuracy)\n",
    "\n",
    "        # Clear the list to free memory.\n",
    "        self.training_step_outputs.clear()\n",
    "\n",
    "        #updating training performance lists\n",
    "        self.train_loss.append(loss_tot.item())\n",
    "        self.train_acc.append(acc_tot.item())\n",
    "\n",
    "\n",
    "        #updating csv logs file\n",
    "        new_row=str(self.train_loss[-1])+\",\"+str(self.train_acc[-1])+\",\"+str(self.val_loss[-1])+\",\"+str(self.val_acc1[-1])+\",\"+str(self.val_acc3[-1])+\",\"+str(self.val_acc5[-1])+\",\"+str(self.val_acc10[-1])\n",
    "        with open(\"./results/logs.csv\",'a',newline='') as file:\n",
    "            #writing row\n",
    "            file.write(new_row+\"\\n\")\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        \"\"\"\n",
    "        Validation step function.\n",
    "\n",
    "        Parameters:\n",
    "        - batch (tuple): Input batch tuple.\n",
    "        - batch_idx (int): Batch index.\n",
    "\n",
    "        Returns:\n",
    "        None\n",
    "        \"\"\"\n",
    "        # Compute the Validation Loss and Accuracy.\n",
    "        loss, acc1, acc3, acc5, acc10, _, _, _ = self._step(batch)\n",
    "\n",
    "        # Create a Dictionary to represent the output of the validation step.\n",
    "        validation_step_output = {\n",
    "            \"val_loss\": loss.item(),\n",
    "            \"val_acc\": acc1.item(),\n",
    "            \"val_acc_3\": acc3.item(),\n",
    "            \"val_acc_5\": acc5.item(),\n",
    "            \"val_acc_10\": acc10.item(),\n",
    "        }\n",
    "\n",
    "        # Append the dictionary to the list.\n",
    "        self.validation_step_outputs.append(validation_step_output)\n",
    "\n",
    "        # Perform logging.\n",
    "        self.log(\"val_loss\", loss, on_epoch=True, prog_bar=True, logger=True)\n",
    "        self.log(\"val_acc\", acc1, on_epoch=True, prog_bar=True, logger=True)\n",
    "        self.log(\"val_acc_3\", acc3, on_epoch=True, prog_bar=True, logger=True)\n",
    "        self.log(\"val_acc_5\", acc5, on_epoch=True, prog_bar=True, logger=True)\n",
    "        self.log(\"val_acc_10\", acc10, on_epoch=True, prog_bar=True, logger=True)\n",
    "\n",
    "    def on_validation_epoch_end(self):\n",
    "        \"\"\"\n",
    "        Method called at the end of the validation epoch.\n",
    "\n",
    "        Returns:\n",
    "        None\n",
    "        \"\"\"\n",
    "        # Calculate the Mean Loss and Accuracy from the list of dictionaries.\n",
    "        loss_tot = torch.tensor([item[\"val_loss\"] for item in self.validation_step_outputs]).mean().to(\"cuda\")\n",
    "        acc_tot = torch.tensor([item[\"val_acc\"] for item in self.validation_step_outputs]).mean().to(\"cuda\")\n",
    "        acc_tot_3 = torch.tensor([item[\"val_acc_3\"] for item in self.validation_step_outputs]).mean().to(\"cuda\")\n",
    "        acc_tot_5 = torch.tensor([item[\"val_acc_5\"] for item in self.validation_step_outputs]).mean().to(\"cuda\")\n",
    "        acc_tot_10 = torch.tensor([item[\"val_acc_10\"] for item in self.validation_step_outputs]).mean().to(\"cuda\")\n",
    "\n",
    "        # Log the mean values.\n",
    "        self.log(\"val_loss\", loss_tot)\n",
    "        self.log(\"val_acc\", acc_tot)\n",
    "        self.log(\"val_acc_3\", acc_tot_3)\n",
    "        self.log(\"val_acc_5\", acc_tot_5)\n",
    "        self.log(\"val_acc_10\", acc_tot_10)\n",
    "\n",
    "        # Print messages.\n",
    "        message_loss = f'Epoch {self.current_epoch} Validation Loss -> {loss_tot}'\n",
    "        message_accuracy = f'      Validation Accuracy -> {acc_tot}'\n",
    "        message_accuracy_3 = f'      Validation Accuracy Top-3 -> {acc_tot_3}'\n",
    "        message_accuracy_5 = f'      Validation Accuracy Top-5-> {acc_tot_5}'\n",
    "        message_accuracy_10 = f'      Validation Accuracy Top-10-> {acc_tot_10}'\n",
    "        print(message_loss + message_accuracy + message_accuracy_3 + message_accuracy_5 + message_accuracy_10)\n",
    "\n",
    "        # Clear the list to free memory.\n",
    "        self.validation_step_outputs.clear()\n",
    "\n",
    "        #updating validation performance lists\n",
    "        self.val_loss.append(loss_tot.item())\n",
    "        self.val_acc1.append(acc_tot.item())\n",
    "        self.val_acc3.append(acc_tot_3.item())\n",
    "        self.val_acc5.append(acc_tot_5.item())\n",
    "        self.val_acc10.append(acc_tot_10.item())\n",
    "\n",
    "    def test_step(self, batch, batch_idx):\n",
    "        \"\"\"\n",
    "        Test step function.\n",
    "\n",
    "        Parameters:\n",
    "        - batch (tuple): Input batch tuple.\n",
    "        - batch_idx (int): Batch index.\n",
    "\n",
    "        Returns:\n",
    "        torch.Tensor: Model predictions.\n",
    "        \"\"\"\n",
    "        x = batch\n",
    "        # Compute the Logits.\n",
    "        preds = self(x)\n",
    "        print(\"The prediction is: \", preds)\n",
    "        return preds\n",
    "\n",
    "    def on_test_epoch_end(self):\n",
    "        \"\"\"\n",
    "        Method called at the end of the test epoch.\n",
    "\n",
    "        Returns:\n",
    "        None\n",
    "        \"\"\"\n",
    "        print(\"Test Epoch Complete.\")\n",
    "\n",
    "    def predict(self, input_image):\n",
    "        \"\"\"\n",
    "        Method called at Inference Time.\n",
    "\n",
    "        Returns:\n",
    "        predicted_labels: prediction over the labels.\n",
    "        \"\"\"\n",
    "\n",
    "        with torch.no_grad():\n",
    "\n",
    "            preds = self(input_image)\n",
    "\n",
    "            # Scale the logits using a Temperature Scaling.\n",
    "            preds_scaled = F.log_softmax(preds / self.temperature, dim=1)\n",
    "\n",
    "            # Get the predicted class labels.\n",
    "            predicted_labels = torch.argmax(preds_scaled, dim=1).cpu().numpy()\n",
    "\n",
    "            return predicted_labels\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        \"\"\"\n",
    "        Configure the optimizer.\n",
    "\n",
    "        Returns:\n",
    "        torch.optim.Optimizer: The optimizer.\n",
    "        \"\"\"\n",
    "        # Configure the Adam Optimizer.\n",
    "        optimizer = optim.Adam(self.parameters(), lr=self.learning_rate, weight_decay=self.weight_decay)\n",
    "        scheduler = CosineAnnealingWarmRestarts(optimizer, T_0=10, T_mult=1, eta_min=0.001)\n",
    "        #scheduler = CosineAnnealingWarmRestarts(optimizer, T_0=10, T_mult=1, eta_min=0.001)\n",
    "        #optimizer, scheduler = get_optimizer_scheduler(\n",
    "        #                                               model,\n",
    "        #                                               lr=self.learning_rate,\n",
    "        #                                               warmup_epochs=self.warmup_epochs,\n",
    "        #                                               num_epochs=self.nepochs,\n",
    "        #                                               weight_decay=self.weight_decay,\n",
    "        #                                               batch_size=self.batch_size\n",
    "        #                                               )\n",
    "\n",
    "        #return optimizer\n",
    "        return {'optimizer': optimizer, 'lr_scheduler': scheduler}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4: CALLBACK DEFINITION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checkpoint CallBack Definition.\n",
    "my_checkpoint_call = ModelCheckpoint(\n",
    "    dirpath=\"./checkpoints/\",\n",
    "    filename=\"Best_Model\",\n",
    "    monitor=\"val_acc\",\n",
    "    mode=\"max\",\n",
    "    save_top_k=1,\n",
    "    save_last=True\n",
    ")\n",
    "\n",
    "# Learning Rate CallBack Definition.\n",
    "my_lr_monitor_call = LearningRateMonitor(logging_interval=\"epoch\")\n",
    "\n",
    "# Early Stopping CallBack Definition.\n",
    "my_early_stopping_call = pl.callbacks.EarlyStopping(monitor=\"val_loss\", patience=50, mode=\"min\", min_delta=0.001)\n",
    "\n",
    "# Progress Bar CallBack Definition.\n",
    "my_progress_bar_call = TQDMProgressBar(refresh_rate=10)\n",
    "\n",
    "# TensorBoardLogger CallBack Definition.\n",
    "#tb_logger = TensorBoardLogger(save_dir=\"./results/logs/\", name=\"ViT\")\n",
    "\n",
    "# CSV CallBack Definition.\n",
    "csv_logger = CSVLogger(\"./results/logs/\", name=\"ViT\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5: MODEL HYPERPAMETERS \\& MODEL INSTANTIATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Instantiate the Adaptive Vision Transformer Model.\n",
    "# Model Hyperparameters-\n",
    "blocks=12\n",
    "heads=3\n",
    "classes=30\n",
    "hidden_dim=192\n",
    "batch=64\n",
    "\n",
    "learning_rate=1.5e-3\n",
    "weight_decay=1.5e-4\n",
    "temperature=0.5\n",
    "class_mlp_ratio=4\n",
    "vit_mlp_ratio=4\n",
    "input_size=(3,224, 224)\n",
    "patches=14\n",
    "\n",
    "number_epochs = 200\n",
    "warmup_epochs = 5\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Halting Hyperparameters.\n",
    "gamma = 5\n",
    "beta = -10\n",
    "alpha_ponder = 5e-4\n",
    "alpha_distribution = 0.1\n",
    "epsilon = 0.01\n",
    "expected_stop_depth=2\n",
    "b_laplace=2 #Set it to \"None\" if not using laplace_distribution\n",
    "\n",
    "model = ViT(input_d = input_size,\n",
    "            batch_size=batch,\n",
    "            n_patches = patches,\n",
    "            n_blocks = blocks,\n",
    "            hidden_d = hidden_dim,\n",
    "            n_heads = heads,\n",
    "            out_d = classes,\n",
    "            lr = learning_rate,\n",
    "            nepochs = number_epochs,\n",
    "            warmup_epochs = warmup_epochs,\n",
    "            wd = weight_decay,\n",
    "            temp = temperature,\n",
    "            cmlp_ratio = class_mlp_ratio,\n",
    "            vmlp_ratio = vit_mlp_ratio\n",
    "        )\n",
    "\n",
    "data_module = AViT_DataModule(\n",
    "    train_data_dir=\"./dataset/nano-imagenet/train/\",\n",
    "    val_data_dir=\"./dataset/nano-imagenet/val/images/\",\n",
    "    test_data_dir=\"./dataset/nano-imagenet/test/images/\",\n",
    "    batch_size=batch\n",
    ")\n",
    "\n",
    "# Setup the Dataloaders.\n",
    "data_module.setup()\n",
    "\n",
    "# Create a PyTorch Lightning Trainer.\n",
    "trainer = pl.Trainer(\n",
    "    max_epochs=number_epochs,\n",
    "    accelerator=\"auto\",\n",
    "    devices=1 if torch.cuda.is_available() else 0,\n",
    "    log_every_n_steps=1,\n",
    "    callbacks=[my_progress_bar_call,\n",
    "               my_checkpoint_call,\n",
    "               my_lr_monitor_call,\n",
    "               my_early_stopping_call,\n",
    "               ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "halting_row=f\"Halting Hyperparameters: gamma={gamma},beta={beta},alpha_ponder={alpha_ponder},alpha_distribution={alpha_distribution},epsilon={epsilon},expected_stop_depth={expected_stop_depth}\"\n",
    "if b_laplace is not None:\n",
    "    halting_row +=f\",b_laplace={b_laplace}\"\n",
    "\n",
    "with open(\"./results/logs.csv\", 'w') as file:\n",
    "    #writing header\n",
    "    perf_header=\"Training Loss\"+\",\"+\"Training Accuracy\"+\",\"+\"Validation Loss\"+\",\"+\"Validation Top-1 Accuracy\"+\",\"+\"Validation Top-3 Accuracy\"+\",\"+\"Validation Top-5 Accuracy\"+\",\"+\"Validation Top-10 Accuracy\"\n",
    "    halt_header=''\n",
    "    for i in range(2*blocks):\n",
    "        if i<blocks:\n",
    "            string=f\"Percentage halted tokens layer_{i}\"\n",
    "        else:\n",
    "            string=f\"Variance halted tokens layer_{i-blocks}\"\n",
    "        halt_header+=\",\"+string\n",
    "    file.write(f\"Model Hypeparameters: input_size={input_size},n_patches={patches},n_blocks={blocks},n_heads={heads},hidden_d={hidden_dim},output_size={classes},batch_size={batch},learning_rate={learning_rate},weight_decay={weight_decay},temp={temperature},class_mlp_ratio={class_mlp_ratio},vit_mlp_ratio={vit_mlp_ratio}\\n\")\n",
    "    file.write(halting_row+\"\\n\")\n",
    "    file.write(perf_header+halt_header+\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6: MODEL TRAINING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "trainer.fit(model.to(\"cuda\"), data_module)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path=\"./results/\"\n",
    "# Plotting Performace metrics\n",
    "def plotter(data, xlabel, ylabel, title, is_halting):\n",
    "    if is_halting:\n",
    "        plt.style.use('bmh')\n",
    "    plt.xticks([i for i in range(len(data))])\n",
    "    plt.plot(data,marker=\"o\")\n",
    "    plt.title(title)\n",
    "    plt.xlabel(xlabel)\n",
    "    plt.ylabel(ylabel)\n",
    "    name=title.replace(\" \",\"_\")\n",
    "    plt.savefig(save_path+f\"{name}.png\")\n",
    "    plt.show()\n",
    "\n",
    "# Removing first element.\n",
    "val_loss=[x for x in model.val_loss[1:]]\n",
    "val_acc1=[x for x in model.val_acc1[1:]]\n",
    "val_acc3=[x for x in model.val_acc3[1:]]\n",
    "val_acc5=[x for x in model.val_acc5[1:]]\n",
    "val_acc10=[x for x in model.val_acc10[1:]]\n",
    "\n",
    "# print(\"Performance lists: \")\n",
    "# print(model.train_loss)\n",
    "# print(model.train_acc)\n",
    "# print(val_loss)\n",
    "# print(val_acc1)\n",
    "# print(val_acc3)\n",
    "# print(val_acc5)\n",
    "# print(val_acc10)\n",
    "# print(model.perc)\n",
    "# print(model.var)\n",
    "\n",
    "# Plotting.\n",
    "plotter(model.train_loss,\"epochs\",\"loss\",\"Train Loss\",False)\n",
    "plotter(model.train_acc,\"epochs\",\"accuracy\",\"Train Accuracy\",False)\n",
    "plotter(val_loss,\"epochs\",\"loss\",\"Validation Loss\",False)\n",
    "plotter(val_acc1,\"epochs\",\"accuracy\",\"Validation Top-1 Accuracy\",False)\n",
    "plotter(val_acc3,\"epochs\",\"accuracy\",\"Validation Top-3 Accuracy\",False)\n",
    "plotter(val_acc5,\"epochs\",\"accuracy\",\"Validation Top-5 Accuracy\",False)\n",
    "plotter(val_acc10,\"epochs\",\"accuracy\",\"Validation Top-10 Accuracy\",False)\n",
    "plotter(model.perc[-1],\"layers\",\"percentage\",\"Percentage Halted Tokens\",True)\n",
    "plotter(model.var[-1],\"layers\",\"variance\",\"Variance Halted Tokens\",True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7: MODEL SAVING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the path of the best Model.\n",
    "best_model_path = my_checkpoint_call.best_model_path\n",
    "\n",
    "# Load the best model from the Checkpoint.\n",
    "best_model = ViT.load_from_checkpoint(\n",
    "                   checkpoint_path=best_model_path,\n",
    "                   input_d = input_size,\n",
    "                   batch_size=batch,\n",
    "                   n_patches = patches,\n",
    "                   n_blocks = blocks,\n",
    "                   hidden_d = hidden_dim,\n",
    "                   n_heads = heads,\n",
    "                   out_d = classes,\n",
    "                   lr = learning_rate,\n",
    "                   nepochs = number_epochs,\n",
    "                   warmup_epochs = warmup_epochs,\n",
    "                   wd = weight_decay,\n",
    "                   temp = temperature,\n",
    "                   cmlp_ratio = class_mlp_ratio,\n",
    "                   vmlp_ratio = vit_mlp_ratio,\n",
    "                   )\n",
    "\n",
    "# Access the Best Model's Accuracy.\n",
    "best_model_accuracy = trainer.checkpoint_callback.best_model_score.item()\n",
    "print(f\"Best Model Accuracy: {best_model_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save it as a pth file.\n",
    "# Specify the path where you want to save the model.\n",
    "model_path = f\"./models/best_model_acc_{best_model_accuracy:.5f}.pth\"\n",
    "\n",
    "# Save the model's state dict to the specified file.\n",
    "torch.save(best_model.state_dict(), model_path)\n",
    "\n",
    "# Save it as a CheckPoint (Specific of PyTorch Lightning = Model State Dictionary + Training State + Optimizer State).\n",
    "# Specify the path where you want to save the model checkpoint.\n",
    "ckpt_path = f\"./models/best_model_acc_{best_model_accuracy:.5f}.ckpt\"\n",
    "\n",
    "# Save the model's state dict to the specified file.\n",
    "torch.save(best_model.state_dict(), ckpt_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
